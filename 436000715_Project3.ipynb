{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fnUuzWWnLKy"
      },
      "source": [
        "This dataset generation code is written using the hints given in the project scope document, and the proof from the reference paper attached along."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bB9Tb_573OUx",
        "outputId": "d9d98da5-a660-43ec-e948-4910b622eec6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/21] Computed h_m(C) for (n=9, k=4, m=2) -> 144.90346620425922\n",
            "[2/21] Computed h_m(C) for (n=9, k=4, m=3) -> 242.89075886905553\n",
            "[3/21] Computed h_m(C) for (n=9, k=4, m=4) -> 1330.2166227995049\n",
            "[4/21] Computed h_m(C) for (n=9, k=4, m=5) -> 4086.4253934219873\n",
            "[5/21] Computed h_m(C) for (n=9, k=5, m=2) -> 321.2006862406292\n",
            "[6/21] Computed h_m(C) for (n=9, k=5, m=3) -> 884.4806452981419\n",
            "[7/21] Computed h_m(C) for (n=9, k=5, m=4) -> 10349.177498422843\n",
            "[8/21] Computed h_m(C) for (n=9, k=6, m=2) -> 898.8751718194876\n",
            "[9/21] Computed h_m(C) for (n=9, k=6, m=3) -> 39566.99255978265\n",
            "[10/21] Computed h_m(C) for (n=10, k=4, m=2) -> 142.99082974010506\n",
            "[11/21] Computed h_m(C) for (n=10, k=4, m=3) -> 158.20899105501928\n",
            "[12/21] Computed h_m(C) for (n=10, k=4, m=4) -> 325.48136135587765\n",
            "[13/21] Computed h_m(C) for (n=10, k=4, m=5) -> 3390.269358512461\n",
            "[14/21] Computed h_m(C) for (n=10, k=4, m=6) -> 64123.66800799458\n",
            "[15/21] Computed h_m(C) for (n=10, k=5, m=2) -> 178.21142924308538\n",
            "[16/21] Computed h_m(C) for (n=10, k=5, m=3) -> 396.26188019848735\n",
            "[17/21] Computed h_m(C) for (n=10, k=5, m=4) -> 3470.7757817283864\n",
            "[18/21] Computed h_m(C) for (n=10, k=5, m=5) -> 8392.361996381358\n",
            "[19/21] Computed h_m(C) for (n=10, k=6, m=2) -> 340.0818600054959\n",
            "[20/21] Computed h_m(C) for (n=10, k=6, m=3) -> 2559.1273103716985\n",
            "[21/21] Computed h_m(C) for (n=10, k=6, m=4) -> 78346.40252421839\n",
            "Dataset saved successfully!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from scipy.optimize import linprog\n",
        "\n",
        "'''\n",
        "This function is used to compute m-height and generate the dataset\n",
        "The code here just checks if it is working fine for each combination of (n, k, m)\n",
        "As this optimization takes GPU operations, to generate data for 1M, a modified version of this code was run on HPRC\n",
        "'''\n",
        "\n",
        "def m_height_linprog_exact(P, n, k, m):\n",
        "\n",
        "    # Constructing generator matrix G = [I_k | P]\n",
        "    G = np.hstack((np.eye(k), P))\n",
        "    indices = list(range(n))\n",
        "\n",
        "    # All the possible psi vectors of length m with their entries ±1\n",
        "    psi_set = list(itertools.product([-1, 1], repeat=m))\n",
        "\n",
        "    # This is the max m-height value, initially 0\n",
        "    h_m_C = 0\n",
        "\n",
        "\n",
        "    '''\n",
        "    This nested function is used to solve the LP optimization of m-height for\n",
        "    a fixed (a, b, X, psi)\n",
        "    '''\n",
        "\n",
        "    def solve_LP(a, b, X, psi):\n",
        "\n",
        "        # Y is the set of remaining coordinates which are not in X, a, or b\n",
        "        Y = list(set(indices) - set(X) - {a, b})\n",
        "\n",
        "        # For psi index mapping, order of coordinates is: a, X, Y, b\n",
        "        thou = [a] + sorted(list(X)) + Y + [b]\n",
        "\n",
        "        # Objective funcion is: maximize psi[0] * <G[:,a], v> where v is a vector in R^k\n",
        "        # Using -c here to reverse the objective, as linprog minimizes\n",
        "        c = np.array([psi[0] * G[i, a] for i in range(k)])\n",
        "\n",
        "        # The inequality constraints\n",
        "        A_ub, b_ub = [], []\n",
        "\n",
        "        # Following are the constraints for j in X\n",
        "        for j in X:\n",
        "            # first\n",
        "            A_ub.append([psi[thou.index(j)] * G[i, j] - psi[0] * G[i, a] for i in range(k)])\n",
        "            b_ub.append(0)\n",
        "            # second\n",
        "            A_ub.append([-psi[thou.index(j)] * G[i, j] for i in range(k)])\n",
        "            b_ub.append(-1)\n",
        "\n",
        "        # Following are the constraints for j in Y\n",
        "        for j in Y:\n",
        "            #The bound is: |<G[:,j], v>| <=1\n",
        "            A_ub.append([G[i, j] for i in range(k)])\n",
        "            b_ub.append(1)\n",
        "            A_ub.append([-G[i, j] for i in range(k)])\n",
        "            b_ub.append(1)\n",
        "\n",
        "        # Equality constraint: <G[:,b], v> =1\n",
        "        A_eq = [[G[i, b] for i in range(k)]]\n",
        "        b_eq = [1]\n",
        "\n",
        "        bounds = [(None, None)] * k\n",
        "        res = linprog(-c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')\n",
        "\n",
        "        # If success then return the optimal value, else return 0\n",
        "        return -res.fun if res.success else 0\n",
        "\n",
        "    # Going over all the valid pairs (a, b)\n",
        "    for a, b in itertools.permutations(indices, 2):\n",
        "        # Going over all (m-1)-size subsets X excluding a, b\n",
        "        for X in itertools.combinations(set(indices) - {a, b}, m - 1):\n",
        "            # Going over all ±1 vectors of length m\n",
        "            for psi in psi_set:\n",
        "                z_val = solve_LP(a, b, X, psi)\n",
        "                # Always storing the maximum height so far.\n",
        "                h_m_C = max(h_m_C, z_val)\n",
        "    return h_m_C\n",
        "\n",
        "# List of 21 (n, k, m) combinations in the project scope\n",
        "combinations = [\n",
        "    (9, 4, 2), (9, 4, 3), (9, 4, 4), (9, 4, 5), (9, 5, 2), (9, 5, 3), (9, 5, 4),\n",
        "    (9, 6, 2), (9, 6, 3), (10, 4, 2), (10, 4, 3), (10, 4, 4), (10, 4, 5), (10, 4, 6),\n",
        "    (10, 5, 2), (10, 5, 3), (10, 5, 4), (10, 5, 5), (10, 6, 2), (10, 6, 3), (10, 6, 4)\n",
        "]\n",
        "\n",
        "# Generating and storing data\n",
        "data = []\n",
        "for i, (n, k, m) in enumerate(combinations, 1):\n",
        "    # P part of the G matrix is generated and value of P ranges between [-100,100]\n",
        "    P = np.random.uniform(-100, 100, size=(k, n - k))\n",
        "    h_m_C = m_height_linprog_exact(P, n, k, m)\n",
        "    data.append((n, k, m, h_m_C, P))\n",
        "    print(f\"[{i}/{len(combinations)}] Computed h_m(C) for (n={n}, k={k}, m={m}) -> {h_m_C}\")\n",
        "\n",
        "# Saving as a DataFrame\n",
        "df = pd.DataFrame(data, columns=['n', 'k', 'm', 'h_m_C', 'P'])\n",
        "df.to_pickle(\"m_height_dataset.pkl\")\n",
        "print(\"Dataset saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HVCJDfBEn_5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from scipy.optimize import linprog\n",
        "import os\n",
        "import joblib\n",
        "from random import choice\n",
        "\n",
        "'''\n",
        "This function is used to compute m-height and generate the dataset\n",
        "The code runs 1M time across combinations to generate the dataset.\n",
        "This was run on HPRC using a SLURM job.\n",
        "'''\n",
        "\n",
        "def m_height_linprog_exact(P, n, k, m):\n",
        "\n",
        "    # Constructing generator matrix G = [I_k | P]\n",
        "    G = np.hstack((np.eye(k), P))\n",
        "    indices = list(range(n))\n",
        "\n",
        "    # All the possible psi vectors of length m with their entries ±1\n",
        "    psi_set = list(itertools.product([-1, 1], repeat=m))\n",
        "\n",
        "    # This is the max m-height value, initially 0\n",
        "    h_m_C = 0\n",
        "\n",
        "\n",
        "    '''\n",
        "    This nested function is used to solve the LP optimization of m-height for\n",
        "    a fixed (a, b, X, psi)\n",
        "    '''\n",
        "\n",
        "    def solve_LP(a, b, X, psi):\n",
        "\n",
        "        # Y is the set of remaining coordinates which are not in X, a, or b\n",
        "        Y = list(set(indices) - set(X) - {a, b})\n",
        "\n",
        "        # For psi index mapping, order of coordinates is: a, X, Y, b\n",
        "        thou = [a] + sorted(list(X)) + Y + [b]\n",
        "\n",
        "        # Objective funcion is: maximize psi[0] * <G[:,a], v> where v is a vector in R^k\n",
        "        # Using -c here to reverse the objective, as linprog minimizes\n",
        "        c = np.array([psi[0] * G[i, a] for i in range(k)])\n",
        "\n",
        "        # The inequality constraints\n",
        "        A_ub, b_ub = [], []\n",
        "\n",
        "        # Following are the constraints for j in X\n",
        "        for j in X:\n",
        "            # first\n",
        "            A_ub.append([psi[thou.index(j)] * G[i, j] - psi[0] * G[i, a] for i in range(k)])\n",
        "            b_ub.append(0)\n",
        "            # second\n",
        "            A_ub.append([-psi[thou.index(j)] * G[i, j] for i in range(k)])\n",
        "            b_ub.append(-1)\n",
        "\n",
        "        # Following are the constraints for j in Y\n",
        "        for j in Y:\n",
        "            #The bound is: |<G[:,j], v>| <=1\n",
        "            A_ub.append([G[i, j] for i in range(k)])\n",
        "            b_ub.append(1)\n",
        "            A_ub.append([-G[i, j] for i in range(k)])\n",
        "            b_ub.append(1)\n",
        "\n",
        "        # Equality constraint: <G[:,b], v> =1\n",
        "        A_eq = [[G[i, b] for i in range(k)]]\n",
        "        b_eq = [1]\n",
        "\n",
        "        bounds = [(None, None)] * k\n",
        "        res = linprog(-c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')\n",
        "\n",
        "        # If success then return the optimal value, else return\n",
        "        return -res.fun if res.success else 0\n",
        "\n",
        "    # Going over all the valid pairs (a, b)\n",
        "    for a, b in itertools.permutations(indices, 2):\n",
        "        # Going over all (m-1)-size subsets X excluding a, b\n",
        "        for X in itertools.combinations(set(indices) - {a, b}, m - 1):\n",
        "            # Going over all ±1 vectors of length m\n",
        "            for psi in psi_set:\n",
        "                z_val = solve_LP(a, b, X, psi)\n",
        "                # Always storing the maximum height so far.\n",
        "                h_m_C = max(h_m_C, z_val)\n",
        "    return h_m_C\n",
        "\n",
        "# List of 21 (n, k, m) combinations in the project scope\n",
        "combinations = [\n",
        "    (9, 4, 2), (9, 4, 3), (9, 4, 4), (9, 4, 5), (9, 5, 2), (9, 5, 3), (9, 5, 4),\n",
        "    (9, 6, 2), (9, 6, 3), (10, 4, 2), (10, 4, 3), (10, 4, 4), (10, 4, 5), (10, 4, 6),\n",
        "    (10, 5, 2), (10, 5, 3), (10, 5, 4), (10, 5, 5), (10, 6, 2), (10, 6, 3), (10, 6, 4)\n",
        "]\n",
        "\n",
        "# Generating and storing data\n",
        "data = []\n",
        "\n",
        "# Generating total 1M samples randomly across all combinations\n",
        "total_samples = 1_000_000\n",
        "\n",
        "for i in enumerate(total_samples):\n",
        "    # Randomly choosing a combination\n",
        "    n, k, m = choice(combinations)\n",
        "    # P part of the G matrix is generated and value of P ranges between [-100,100]\n",
        "    P = np.random.uniform(-100, 100, size=(k, n - k))\n",
        "    h_m_C = m_height_linprog_exact(P, n, k, m)\n",
        "    data.append((n, k, m, h_m_C, P))\n",
        "    # print(f\"[{i}/{len(combinations)}] Computed h_m(C) for (n={n}, k={k}, m={m}) -> {h_m_C}\")\n",
        "\n",
        "# Saving as a DataFrame in my directory\n",
        "df = pd.DataFrame(data, columns=['n', 'k', 'm', 'h_m_C', 'P'])\n",
        "output_dir = os.environ.get(\"SCRATCH\") + \"/dipanwita22rano/dlproject\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "output_path = os.path.join(output_dir, \"m_height_dataset.pkl\")\n",
        "with open(output_path, 'wb') as f:\n",
        "    joblib.dump(df, f)\n",
        "print(\"Dataset saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKlrPKCKMX0I",
        "outputId": "c608cbb5-85e7-4bb2-9760-e77eb27df67c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "    n  k  m         h_m_C                                                  P\n",
            "0  10  4  3    180.681884  [[0.41332842078512044, 70.03763016732799, 92.9...\n",
            "1   9  6  3  29425.835225  [[-22.39439891822049, -45.59568035361643, 84.5...\n",
            "2  10  4  4    590.143407  [[-98.04865191290197, 55.176558968450024, -47....\n",
            "3   9  6  3   6838.797140  [[-72.01756032528372, -96.84222090558315, -97....\n",
            "4   9  6  3   5219.964621  [[86.98714113704173, 62.11282763418615, -49.67...\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/My Drive/m_height_dataset.pkl'\n",
        "with open(file_path, 'rb') as f:\n",
        "    df = joblib.load(f)\n",
        "output_path = '/content/drive/My Drive/m_height_dataset_.pkl'\n",
        "with open(output_path, 'wb') as f:\n",
        "    joblib.dump(df, f)\n",
        "print(df.head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Better Architecture Experiment - Using the same Transformer model as in previous projects, but using more regularization here, and epochs has been increased.\n",
        "\n",
        "* It was observed that loss values increased with larger m, making higher-m groups harder to predict accurately.\n",
        "\n",
        "* Motivation: introduce stronger regularization to models corresponding to larger m values to stabilize training and prevent overfitting on noisy or more complex data.\n",
        "\n",
        "* L2 regularization was added to the Dense layers to encourage smoother predictions especially where learning became more unstable for high m.\n",
        "\n",
        "* Although regularization improved stability, it sometimes caused slightly worse predictive performance (higher RMSLE) due to the reduced model flexibility.\n",
        "\n",
        "* Overall, this trade-off aimed to prioritize more consistent behavior across varying m values rather than overfitting the easier (small m) cases only.\n",
        "\n",
        "But finally even this experiment failed, with slightly poorer results compared to the previous submitted model."
      ],
      "metadata": {
        "id": "KabxjUrahsEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from tensorflow import keras\n",
        "from keras import layers, regularizers\n",
        "import tensorflow as tf\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/My Drive/m_height_dataset.pkl'\n",
        "with open(file_path, 'rb') as f:\n",
        "    df = joblib.load(f)\n",
        "\n",
        "df['k_val'] = df['P'].apply(lambda x: x.shape[0])\n",
        "max_k = df['k_val'].max()\n",
        "print(f\"Maximum k (rows in P): {max_k}\")\n",
        "\n",
        "'''\n",
        "  Dataset Split\n",
        "  Test = 15% of df\n",
        "  Train = 85% * (85%) of df\n",
        "  Validation = 15% * (85%) of df\n",
        "'''\n",
        "train_val_df, test_df = train_test_split(df, test_size=0.15, random_state=42)\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.15, random_state=42)\n",
        "\n",
        "'''\n",
        "  Introducing a weightles loss in the preprocessing function\n",
        "'''\n",
        "def preprocess_group_with_weight(group_df):\n",
        "    X_list, y_list, weights_list = [], [], []\n",
        "    for _, row in group_df.iterrows():\n",
        "        P = np.array(row['P']).astype(np.float32)\n",
        "        n, k, m = row['n'], row['k'], row['m']\n",
        "        meta = np.array([n, k, m], dtype=np.float32)\n",
        "\n",
        "        row_features = []\n",
        "        for i in range(P.shape[0]):\n",
        "            pos_encoding = np.zeros(max_k)\n",
        "            pos_encoding[i] = 1.0\n",
        "            features = np.concatenate([P[i], meta, pos_encoding])\n",
        "            row_features.append(features)\n",
        "\n",
        "        X = np.array(row_features)\n",
        "        X_list.append(X)\n",
        "        y_list.append(np.log(row['h_m_C']))\n",
        "        # Optional weight scaling here\n",
        "        weights_list.append(1.0 / (m + 1))\n",
        "\n",
        "    return np.array(X_list), np.array(y_list), np.array(weights_list)\n",
        "\n",
        "# Same old Transformer model\n",
        "def build_transformer_model(input_shape):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = layers.LayerNormalization()(inputs)\n",
        "    x = layers.MultiHeadAttention(num_heads=2, key_dim=8)(x, x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "    x = layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "    outputs = layers.Dense(1)(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "results = []\n",
        "global_y_true = []\n",
        "global_y_pred = []\n",
        "\n",
        "unique_groups = sorted(train_df.groupby(['n', 'k', 'm']).groups.keys())\n",
        "os.makedirs('/content/models', exist_ok=True)\n",
        "\n",
        "for (n, k, m) in unique_groups:\n",
        "    print(f\"\\nTraining model for (n={n}, k={k}, m={m})\")\n",
        "\n",
        "    train_group = train_df[(train_df['n'] == n) & (train_df['k'] == k) & (train_df['m'] == m)]\n",
        "    val_group = val_df[(val_df['n'] == n) & (val_df['k'] == k) & (val_df['m'] == m)]\n",
        "    test_group = test_df[(test_df['n'] == n) & (test_df['k'] == k) & (test_df['m'] == m)]\n",
        "\n",
        "    X_train, y_train, weights_train = preprocess_group_with_weight(train_group)\n",
        "    X_val, y_val, weights_val = preprocess_group_with_weight(val_group)\n",
        "    X_test, y_test_log, weights_test = preprocess_group_with_weight(test_group)\n",
        "\n",
        "    model = build_transformer_model(input_shape=X_train.shape[1:])\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        sample_weight=weights_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=80,\n",
        "        batch_size=32,\n",
        "        verbose=0,\n",
        "        callbacks=[keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]\n",
        "    )\n",
        "\n",
        "    model_path = f'/content/models/model_n{n}_k{k}_m{m}.h5'\n",
        "    model.save(model_path)\n",
        "    print(f\"Model saved to {model_path}\")\n",
        "\n",
        "    y_pred_log = model.predict(X_test).flatten()\n",
        "    y_pred = np.exp(y_pred_log)\n",
        "    y_true = np.exp(y_test_log)\n",
        "\n",
        "    y_pred = np.maximum(y_pred, 1.0)\n",
        "    y_true = np.maximum(y_true, 1.0)\n",
        "\n",
        "    global_y_pred.extend(y_pred)\n",
        "    global_y_true.extend(y_true)\n",
        "\n",
        "    y_pred_log2 = np.log2(y_pred)\n",
        "    y_true_log2 = np.log2(y_true)\n",
        "    rmsle = np.sqrt(mean_squared_log_error(y_true_log2, y_pred_log2))\n",
        "    results.append(((n, k, m), rmsle))\n",
        "    print(f\"RMSLE (log base 2): {rmsle:.4f}\")\n",
        "\n",
        "# Evaluation metrics globally\n",
        "global_y_pred = np.array(global_y_pred)\n",
        "global_y_true = np.array(global_y_true)\n",
        "\n",
        "global_y_pred_log2 = np.log2(global_y_pred)\n",
        "global_y_true_log2 = np.log2(global_y_true)\n",
        "\n",
        "global_cost = ((global_y_pred_log2 - global_y_true_log2) ** 2).mean()\n",
        "global_rmsle = np.sqrt(mean_squared_log_error(global_y_true_log2, global_y_pred_log2))\n",
        "\n",
        "print(\"\\n=== Summary of Group-wise RMSLE ===\")\n",
        "for (n, k, m), rmsle in results:\n",
        "    print(f\"Group (n={n}, k={k}, m={m}): RMSLE (log base 2) = {rmsle:.4f}\")\n",
        "\n",
        "print(\"\\n=== Global Evaluation ===\")\n",
        "print(f\"Global Cost (σ) = {global_cost:.4f}\")\n",
        "print(f\"Global RMSLE (log base 2) = {global_rmsle:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRhmvisJh2Jo",
        "outputId": "2351b740-d518-42d5-f4b3-67f259fadb63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Maximum k (rows in P): 6\n",
            "\n",
            "Training model for (n=9, k=4, m=2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n9_k4_m2.h5\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "RMSLE (log base 2): 0.0538\n",
            "\n",
            "Training model for (n=9, k=4, m=3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n9_k4_m3.h5\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "RMSLE (log base 2): 0.0520\n",
            "\n",
            "Training model for (n=9, k=4, m=4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n9_k4_m4.h5\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "RMSLE (log base 2): 0.0829\n",
            "\n",
            "Training model for (n=9, k=4, m=5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n9_k4_m5.h5\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.1156\n",
            "\n",
            "Training model for (n=9, k=5, m=2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n9_k5_m2.h5\n",
            "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "RMSLE (log base 2): 0.0508\n",
            "\n",
            "Training model for (n=9, k=5, m=3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n9_k5_m3.h5\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "RMSLE (log base 2): 0.0802\n",
            "\n",
            "Training model for (n=9, k=5, m=4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n9_k5_m4.h5\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.1101\n",
            "\n",
            "Training model for (n=9, k=6, m=2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n9_k6_m2.h5\n",
            "\u001b[1m394/394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "RMSLE (log base 2): 0.0741\n",
            "\n",
            "Training model for (n=9, k=6, m=3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n9_k6_m3.h5\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.1151\n",
            "\n",
            "Training model for (n=10, k=4, m=2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k4_m2.h5\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "RMSLE (log base 2): 0.1384\n",
            "\n",
            "Training model for (n=10, k=4, m=3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k4_m3.h5\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.0370\n",
            "\n",
            "Training model for (n=10, k=4, m=4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k4_m4.h5\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.0550\n",
            "\n",
            "Training model for (n=10, k=4, m=5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k4_m5.h5\n",
            "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.0825\n",
            "\n",
            "Training model for (n=10, k=4, m=6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k4_m6.h5\n",
            "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.1110\n",
            "\n",
            "Training model for (n=10, k=5, m=2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k5_m2.h5\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.0387\n",
            "\n",
            "Training model for (n=10, k=5, m=3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k5_m3.h5\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "RMSLE (log base 2): 0.0584\n",
            "\n",
            "Training model for (n=10, k=5, m=4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k5_m4.h5\n",
            "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "RMSLE (log base 2): 0.0792\n",
            "\n",
            "Training model for (n=10, k=5, m=5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k5_m5.h5\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "RMSLE (log base 2): 0.1049\n",
            "\n",
            "Training model for (n=10, k=6, m=2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k6_m2.h5\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "RMSLE (log base 2): 0.0502\n",
            "\n",
            "Training model for (n=10, k=6, m=3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k6_m3.h5\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "RMSLE (log base 2): 0.0766\n",
            "\n",
            "Training model for (n=10, k=6, m=4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Meta Learner Model - Experimental\n",
        "\n",
        "This is an ensemble approach. It includes:\n",
        "* A Transformer model was trained to predict log(h_m_C) from the processed input.\n",
        "* A Ridge regression meta-learner was added on top of Transformer predictions.\n",
        "* The Ridge model combines predictions (if multiple seeds/models are used) and acts as a second-stage smoother to correct Transformer biases or overfitting, especially where m-value is high.\n",
        "\n",
        "Key Changes: Instead of using only one neural network, predictions are regularized and stabilized by training a simple linear model (Ridge) over Transformer outputs.\n",
        "\n",
        "\n",
        "Even thiug it shows comparative results, still it fails to beat the transformer model used below."
      ],
      "metadata": {
        "id": "nY_jUzfJgF4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from keras import layers, regularizers\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/My Drive/m_height_dataset.pkl'\n",
        "with open(file_path, 'rb') as f:\n",
        "    df = joblib.load(f)\n",
        "\n",
        "df['k_val'] = df['P'].apply(lambda x: x.shape[0])\n",
        "max_k = df['k_val'].max()\n",
        "print(f\"Maximum k (rows in P): {max_k}\")\n",
        "\n",
        "'''\n",
        "  Splitting the dataset here:\n",
        "  Test = 15% of df\n",
        "  Train = 85% * (85%) of df\n",
        "  Validation = 15% * (85%) of df\n",
        "'''\n",
        "train_val_df, test_df = train_test_split(df, test_size=0.15, random_state=42)\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.15, random_state=42)\n",
        "\n",
        "\n",
        "def preprocess_group(group_df):\n",
        "    X_list, y_list = [], []\n",
        "    for _, row in group_df.iterrows():\n",
        "        P = np.array(row['P']).astype(np.float32)\n",
        "        n, k, m = row['n'], row['k'], row['m']\n",
        "        meta = np.array([n, k, m], dtype=np.float32)\n",
        "\n",
        "        row_features = []\n",
        "        for i in range(P.shape[0]):\n",
        "            pos_encoding = np.zeros(max_k)\n",
        "            pos_encoding[i] = 1.0\n",
        "            features = np.concatenate([P[i], meta, pos_encoding])\n",
        "            row_features.append(features)\n",
        "\n",
        "        X = np.array(row_features)\n",
        "        X_list.append(X)\n",
        "        y_list.append(np.log(row['h_m_C']))\n",
        "\n",
        "    return np.array(X_list), np.array(y_list)\n",
        "\n",
        "# Building the initial transformer model\n",
        "def build_transformer_model(input_shape):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = layers.LayerNormalization()(inputs)\n",
        "    x = layers.MultiHeadAttention(num_heads=2, key_dim=8)(x, x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "    x = layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "    outputs = layers.Dense(1)(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "unique_groups = sorted(train_df.groupby(['n', 'k', 'm']).groups.keys())\n",
        "os.makedirs('/content/models', exist_ok=True)\n",
        "\n",
        "# Storing one Ridge per group here\n",
        "ridge_models = {}\n",
        "global_true, global_pred = [], []\n",
        "\n",
        "for (n, k, m) in unique_groups:\n",
        "    print(f\"\\nTraining group (n={n}, k={k}, m={m})\")\n",
        "\n",
        "    train_group = train_df[(train_df['n'] == n) & (train_df['k'] == k) & (train_df['m'] == m)]\n",
        "    val_group = val_df[(val_df['n'] == n) & (val_df['k'] == k) & (val_df['m'] == m)]\n",
        "    test_group = test_df[(test_df['n'] == n) & (test_df['k'] == k) & (test_df['m'] == m)]\n",
        "\n",
        "    if len(train_group) == 0 or len(val_group) == 0 or len(test_group) == 0:\n",
        "        print(\"Skipping due to insufficient data.\")\n",
        "        continue\n",
        "\n",
        "    X_train, y_train = preprocess_group(train_group)\n",
        "    X_val, y_val = preprocess_group(val_group)\n",
        "    X_test, y_test = preprocess_group(test_group)\n",
        "\n",
        "    models = []\n",
        "    meta_train, meta_val, meta_test = [], [], []\n",
        "\n",
        "    # keeping seeds to 1\n",
        "    for seed in range(1):\n",
        "        model = build_transformer_model(X_train.shape[1:])\n",
        "        model.fit(\n",
        "            X_train, y_train,\n",
        "            validation_data=(X_val, y_val),\n",
        "            epochs=50,\n",
        "            batch_size=32,\n",
        "            verbose=0,\n",
        "            callbacks=[keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]\n",
        "        )\n",
        "        models.append(model)\n",
        "\n",
        "        model_save_path = f\"/content/models/transformer_n{n}_k{k}_m{m}_seed{seed}.keras\"\n",
        "        model.save(model_save_path)\n",
        "        print(f\"Saved model: {model_save_path}\")\n",
        "\n",
        "        meta_train.append(model.predict(X_train).flatten())\n",
        "        meta_val.append(model.predict(X_val).flatten())\n",
        "        meta_test.append(model.predict(X_test).flatten())\n",
        "\n",
        "    # Stacking predictions for each group\n",
        "    meta_train = np.vstack(meta_train).T\n",
        "    meta_val = np.vstack(meta_val).T\n",
        "    meta_test = np.vstack(meta_test).T\n",
        "\n",
        "    # Training the Ridge meta-learner on each group\n",
        "    ridge = Ridge(alpha=1.0)\n",
        "    ridge.fit(meta_train, y_train)\n",
        "\n",
        "    ridge_save_path = f\"/content/models/ridge_n{n}_k{k}_m{m}.joblib\"\n",
        "    joblib.dump(ridge, ridge_save_path)\n",
        "    print(f\"Saved Ridge model: {ridge_save_path}\")\n",
        "\n",
        "    pred_test = ridge.predict(meta_test)\n",
        "\n",
        "    # Storing each group predictions\n",
        "    global_true.append(np.exp(y_test))\n",
        "    global_pred.append(np.exp(pred_test))\n",
        "    ridge_models[(n, k, m)] = ridge\n",
        "\n",
        "\n",
        "if len(global_true) > 0 and len(global_pred) > 0:\n",
        "    global_true = np.concatenate(global_true)\n",
        "    global_pred = np.concatenate(global_pred)\n",
        "\n",
        "    global_pred = np.maximum(global_pred, 1.0)\n",
        "    global_true = np.maximum(global_true, 1.0)\n",
        "\n",
        "    global_rmsle = np.sqrt(mean_squared_log_error(np.log2(global_true), np.log2(global_pred)))\n",
        "    global_cost = np.mean((np.log2(global_true) - np.log2(global_pred))**2)\n",
        "\n",
        "    print(f\"\\nGlobal Ensemble RMSLE (log base 2): {global_rmsle:.4f}\")\n",
        "    print(f\"Global Test Cost σ: {global_cost:.4f}\")\n",
        "else:\n",
        "    print(\"\\nNo models were trained due to insufficient data!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDzGmCEl1vlX",
        "outputId": "1c3f5ff9-a9b5-4bdd-fe87-a09f19188732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Maximum k (rows in P): 6\n",
            "\n",
            "Training group (n=9, k=4, m=2)\n",
            "Saved model: /content/models/transformer_n9_k4_m2_seed0.keras\n",
            "\u001b[1m945/945\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Saved Ridge model: /content/models/ridge_n9_k4_m2.joblib\n",
            "\n",
            "Training group (n=9, k=4, m=3)\n",
            "Saved model: /content/models/transformer_n9_k4_m3_seed0.keras\n",
            "\u001b[1m945/945\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
            "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Saved Ridge model: /content/models/ridge_n9_k4_m3.joblib\n",
            "\n",
            "Training group (n=9, k=4, m=4)\n",
            "Saved model: /content/models/transformer_n9_k4_m4_seed0.keras\n",
            "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Saved Ridge model: /content/models/ridge_n9_k4_m4.joblib\n",
            "\n",
            "Training group (n=9, k=4, m=5)\n",
            "Saved model: /content/models/transformer_n9_k4_m5_seed0.keras\n",
            "\u001b[1m945/945\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Saved Ridge model: /content/models/ridge_n9_k4_m5.joblib\n",
            "\n",
            "Training group (n=9, k=5, m=2)\n",
            "Saved model: /content/models/transformer_n9_k5_m2_seed0.keras\n",
            "\u001b[1m1260/1260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Saved Ridge model: /content/models/ridge_n9_k5_m2.joblib\n",
            "\n",
            "Training group (n=9, k=5, m=3)\n",
            "Saved model: /content/models/transformer_n9_k5_m3_seed0.keras\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Saved Ridge model: /content/models/ridge_n9_k5_m3.joblib\n",
            "\n",
            "Training group (n=9, k=5, m=4)\n",
            "Saved model: /content/models/transformer_n9_k5_m4_seed0.keras\n",
            "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Saved Ridge model: /content/models/ridge_n9_k5_m4.joblib\n",
            "\n",
            "Training group (n=9, k=6, m=2)\n",
            "Saved model: /content/models/transformer_n9_k6_m2_seed0.keras\n",
            "\u001b[1m1879/1879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step\n",
            "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m394/394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Saved Ridge model: /content/models/ridge_n9_k6_m2.joblib\n",
            "\n",
            "Training group (n=9, k=6, m=3)\n",
            "Saved model: /content/models/transformer_n9_k6_m3_seed0.keras\n",
            "\u001b[1m1894/1894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Saved Ridge model: /content/models/ridge_n9_k6_m3.joblib\n",
            "\n",
            "Training group (n=10, k=4, m=2)\n",
            "Saved model: /content/models/transformer_n10_k4_m2_seed0.keras\n",
            "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Saved Ridge model: /content/models/ridge_n10_k4_m2.joblib\n",
            "\n",
            "Training group (n=10, k=4, m=3)\n",
            "Saved model: /content/models/transformer_n10_k4_m3_seed0.keras\n",
            "\u001b[1m759/759\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Saved Ridge model: /content/models/ridge_n10_k4_m3.joblib\n",
            "\n",
            "Training group (n=10, k=4, m=4)\n",
            "Saved model: /content/models/transformer_n10_k4_m4_seed0.keras\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Saved Ridge model: /content/models/ridge_n10_k4_m4.joblib\n",
            "\n",
            "Training group (n=10, k=4, m=5)\n",
            "Saved model: /content/models/transformer_n10_k4_m5_seed0.keras\n",
            "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Saved Ridge model: /content/models/ridge_n10_k4_m5.joblib\n",
            "\n",
            "Training group (n=10, k=4, m=6)\n",
            "Saved model: /content/models/transformer_n10_k4_m6_seed0.keras\n",
            "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Saved Ridge model: /content/models/ridge_n10_k4_m6.joblib\n",
            "\n",
            "Training group (n=10, k=5, m=2)\n",
            "Saved model: /content/models/transformer_n10_k5_m2_seed0.keras\n",
            "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Saved Ridge model: /content/models/ridge_n10_k5_m2.joblib\n",
            "\n",
            "Training group (n=10, k=5, m=3)\n",
            "Saved model: /content/models/transformer_n10_k5_m3_seed0.keras\n",
            "\u001b[1m942/942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Saved Ridge model: /content/models/ridge_n10_k5_m3.joblib\n",
            "\n",
            "Training group (n=10, k=5, m=4)\n",
            "Saved model: /content/models/transformer_n10_k5_m4_seed0.keras\n",
            "\u001b[1m949/949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Saved Ridge model: /content/models/ridge_n10_k5_m4.joblib\n",
            "\n",
            "Training group (n=10, k=5, m=5)\n",
            "Saved model: /content/models/transformer_n10_k5_m5_seed0.keras\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Saved Ridge model: /content/models/ridge_n10_k5_m5.joblib\n",
            "\n",
            "Training group (n=10, k=6, m=2)\n",
            "Saved model: /content/models/transformer_n10_k6_m2_seed0.keras\n",
            "\u001b[1m1253/1253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Saved Ridge model: /content/models/ridge_n10_k6_m2.joblib\n",
            "\n",
            "Training group (n=10, k=6, m=3)\n",
            "Saved model: /content/models/transformer_n10_k6_m3_seed0.keras\n",
            "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Saved Ridge model: /content/models/ridge_n10_k6_m3.joblib\n",
            "\n",
            "Training group (n=10, k=6, m=4)\n",
            "Saved model: /content/models/transformer_n10_k6_m4_seed0.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Saved Ridge model: /content/models/ridge_n10_k6_m4.joblib\n",
            "\n",
            "Global Ensemble RMSLE (log base 2): 0.0848\n",
            "Global Test Cost σ: 1.4097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KlJdDNyHy3_"
      },
      "source": [
        "This is the final model I came up with, with the lowest RMSLE amongst all other methods that i tried. This set of 21 models use transformer models, with one-hot encoding of row indices.\n",
        "\n",
        "Other models that I had tried were:\n",
        "* Single general model of feed forward architecture. It consisted of 4 layers, regularization, and an extensive hyperparameter tuning was done on it. Test RMSLE was way higher than validation.\n",
        "* 21 models for each combination of (n, k, m) but all feed forward. Even though this reduced the RMSLE, but it predicted same values for a combination of (n, k, m). Basically this model only learnt a value for each combination, which would minimize the loss.\n",
        "* As P is a matrix, I thought of using CNN, to have a 2D input. But this proved to be the most adverserial, having RMSLE even as high as 57. Thus, it proved that for m-height calculation, there is no spatial relationship between the matrix cell values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-npH4sqHz11",
        "outputId": "a2f84e1a-24d1-4bea-84fd-5e09ae2a1d63"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Maximum k (rows in P): 6\n",
            "\n",
            "Training model for (n=9, k=4, m=2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to /content/models/model_n9_k4_m2.h5\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "RMSLE (log base 2): 0.0526\n",
            "\n",
            "Training model for (n=9, k=4, m=3)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to /content/models/model_n9_k4_m3.h5\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.0524\n",
            "\n",
            "Training model for (n=9, k=4, m=4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to /content/models/model_n9_k4_m4.h5\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "RMSLE (log base 2): 0.0829\n",
            "\n",
            "Training model for (n=9, k=4, m=5)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to /content/models/model_n9_k4_m5.h5\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.1155\n",
            "\n",
            "Training model for (n=9, k=5, m=2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to /content/models/model_n9_k5_m2.h5\n",
            "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.0506\n",
            "\n",
            "Training model for (n=9, k=5, m=3)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to /content/models/model_n9_k5_m3.h5\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "RMSLE (log base 2): 0.0795\n",
            "\n",
            "Training model for (n=9, k=5, m=4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to /content/models/model_n9_k5_m4.h5\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "RMSLE (log base 2): 0.1094\n",
            "\n",
            "Training model for (n=9, k=6, m=2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to /content/models/model_n9_k6_m2.h5\n",
            "\u001b[1m394/394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.0716\n",
            "\n",
            "Training model for (n=9, k=6, m=3)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to /content/models/model_n9_k6_m3.h5\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.1152\n",
            "\n",
            "Training model for (n=10, k=4, m=2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to /content/models/model_n10_k4_m2.h5\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "RMSLE (log base 2): 0.1386\n",
            "\n",
            "Training model for (n=10, k=4, m=3)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to /content/models/model_n10_k4_m3.h5\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.0374\n",
            "\n",
            "Training model for (n=10, k=4, m=4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to /content/models/model_n10_k4_m4.h5\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "RMSLE (log base 2): 0.0552\n",
            "\n",
            "Training model for (n=10, k=4, m=5)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to /content/models/model_n10_k4_m5.h5\n",
            "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.0824\n",
            "\n",
            "Training model for (n=10, k=4, m=6)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to /content/models/model_n10_k4_m6.h5\n",
            "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "RMSLE (log base 2): 0.1110\n",
            "\n",
            "Training model for (n=10, k=5, m=2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to /content/models/model_n10_k5_m2.h5\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.0382\n",
            "\n",
            "Training model for (n=10, k=5, m=3)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to /content/models/model_n10_k5_m3.h5\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.0581\n",
            "\n",
            "Training model for (n=10, k=5, m=4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to /content/models/model_n10_k5_m4.h5\n",
            "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "RMSLE (log base 2): 0.0786\n",
            "\n",
            "Training model for (n=10, k=5, m=5)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to /content/models/model_n10_k5_m5.h5\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.1044\n",
            "\n",
            "Training model for (n=10, k=6, m=2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k6_m2.h5\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.0505\n",
            "\n",
            "Training model for (n=10, k=6, m=3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k6_m3.h5\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "RMSLE (log base 2): 0.0770\n",
            "\n",
            "Training model for (n=10, k=6, m=4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k6_m4.h5\n",
            "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "RMSLE (log base 2): 0.1030\n",
            "\n",
            "=== Summary of Results ===\n",
            "Group (n=9, k=4, m=2): RMSLE (log base 2) = 0.0526\n",
            "Group (n=9, k=4, m=3): RMSLE (log base 2) = 0.0524\n",
            "Group (n=9, k=4, m=4): RMSLE (log base 2) = 0.0829\n",
            "Group (n=9, k=4, m=5): RMSLE (log base 2) = 0.1155\n",
            "Group (n=9, k=5, m=2): RMSLE (log base 2) = 0.0506\n",
            "Group (n=9, k=5, m=3): RMSLE (log base 2) = 0.0795\n",
            "Group (n=9, k=5, m=4): RMSLE (log base 2) = 0.1094\n",
            "Group (n=9, k=6, m=2): RMSLE (log base 2) = 0.0716\n",
            "Group (n=9, k=6, m=3): RMSLE (log base 2) = 0.1152\n",
            "Group (n=10, k=4, m=2): RMSLE (log base 2) = 0.1386\n",
            "Group (n=10, k=4, m=3): RMSLE (log base 2) = 0.0374\n",
            "Group (n=10, k=4, m=4): RMSLE (log base 2) = 0.0552\n",
            "Group (n=10, k=4, m=5): RMSLE (log base 2) = 0.0824\n",
            "Group (n=10, k=4, m=6): RMSLE (log base 2) = 0.1110\n",
            "Group (n=10, k=5, m=2): RMSLE (log base 2) = 0.0382\n",
            "Group (n=10, k=5, m=3): RMSLE (log base 2) = 0.0581\n",
            "Group (n=10, k=5, m=4): RMSLE (log base 2) = 0.0786\n",
            "Group (n=10, k=5, m=5): RMSLE (log base 2) = 0.1044\n",
            "Group (n=10, k=6, m=2): RMSLE (log base 2) = 0.0505\n",
            "Group (n=10, k=6, m=3): RMSLE (log base 2) = 0.0770\n",
            "Group (n=10, k=6, m=4): RMSLE (log base 2) = 0.1030\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from tensorflow import keras\n",
        "from keras import layers, regularizers\n",
        "import tensorflow as tf\n",
        "\n",
        "'''\n",
        "  The dataset was saved to my google drive, so that I do not need to repeatedly\n",
        "  upload it to my Colab runtime.\n",
        "'''\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/My Drive/m_height_dataset.pkl'\n",
        "with open(file_path, 'rb') as f:\n",
        "    df = joblib.load(f)\n",
        "\n",
        "'''\n",
        "  Computing the maximum number of rows in P for Positional Encoding.\n",
        "  It is used to fix the size of one-hot encoding\n",
        "  This gets the maximum value seen across all samples,\n",
        "  so it must be 6 according to the project scope, else error in dataset generation.\n",
        "'''\n",
        "df['k_val'] = df['P'].apply(lambda x: x.shape[0])\n",
        "max_k = df['k_val'].max()\n",
        "print(f\"Maximum k (rows in P): {max_k}\")\n",
        "\n",
        "'''\n",
        "  Splitting the dataset here:\n",
        "  Test = 15% of df\n",
        "  Train = 85% * (85%) of df\n",
        "  Validation = 15% * (85%) of df\n",
        "'''\n",
        "train_val_df, test_df = train_test_split(df, test_size=0.15, random_state=42)\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.15, random_state=42)\n",
        "\n",
        "'''\n",
        "  The following preprocessing function:\n",
        "  Adds metadata (n, k, m) and positional encoding to each row of P\n",
        "  I tested without adding metadata, as anyways making individual models for each combination\n",
        "  But the results were adversarial with poor RMSLE values\n",
        "\n",
        "  Output shape: (k, feature_dim) where feature_dim = (columns in P + 3 metadata + max_k one-hot)\n",
        "  Target: log(h_m_C)\n",
        "  I tested the target without its log value, that is, the actual m-height.\n",
        "  But the RMSLE is better when the model is trained on log(m-height)\n",
        "'''\n",
        "def preprocess_group(group_df):\n",
        "    X_list, y_list = [], []\n",
        "    for _, row in group_df.iterrows():\n",
        "        # P has the shape (k, n-k)\n",
        "        P = np.array(row['P']).astype(np.float32)\n",
        "        n, k, m = row['n'], row['k'], row['m']\n",
        "        meta = np.array([n, k, m], dtype=np.float32)\n",
        "\n",
        "        row_features = []\n",
        "        for i in range(P.shape[0]):\n",
        "            pos_encoding = np.zeros(max_k)\n",
        "            # One-hot encoding the row index here\n",
        "            pos_encoding[i] = 1.0\n",
        "            features = np.concatenate([P[i], meta, pos_encoding])\n",
        "            row_features.append(features)\n",
        "\n",
        "        X = np.array(row_features)\n",
        "        X_list.append(X)\n",
        "        # Log scaling the target here\n",
        "        y_list.append(np.log(row['h_m_C']))\n",
        "    return np.array(X_list), np.array(y_list)\n",
        "\n",
        "'''\n",
        "  After much experimentation, developed a transformer based model.\n",
        "  This stems from the idea that m-height may depend on interactions between different rows.\n",
        "  Thus a transformer can model pairwise and gobal dependencies via self-attention.\n",
        "\n",
        "  Using transformer is better than fully connected layers alone because,\n",
        "  MLPs treat all rows flatly and independently,\n",
        "  CNNs assume local patterns, which is not present in a mathematical concept,\n",
        "  Thus transformers can learn attention weights dynamically across all rows.\n",
        "'''\n",
        "def build_transformer_model(input_shape):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    # Normalization\n",
        "    x = layers.LayerNormalization()(inputs)\n",
        "    # Self-attention\n",
        "    x = layers.MultiHeadAttention(num_heads=2, key_dim=8)(x, x)\n",
        "    # For variable-length inputs\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "    # Dense layer with L2 regularization\n",
        "    x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "    x = layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "    # Finally predict a single log(h_m_C) value\n",
        "    outputs = layers.Dense(1)(x)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    # MSE loss is being used in log-scale\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# Training, saving and evaluating model for each combination of (n, k, m) groups\n",
        "results = []\n",
        "unique_groups = sorted(train_df.groupby(['n', 'k', 'm']).groups.keys())\n",
        "\n",
        "os.makedirs('/content/models', exist_ok=True)\n",
        "\n",
        "for (n, k, m) in unique_groups:\n",
        "    print(f\"\\nTraining model for (n={n}, k={k}, m={m})\")\n",
        "\n",
        "    # Filtering group-specific data from each dataset split\n",
        "    train_group = train_df[(train_df['n'] == n) & (train_df['k'] == k) & (train_df['m'] == m)]\n",
        "    val_group = val_df[(val_df['n'] == n) & (val_df['k'] == k) & (val_df['m'] == m)]\n",
        "    test_group = test_df[(test_df['n'] == n) & (test_df['k'] == k) & (test_df['m'] == m)]\n",
        "\n",
        "    # Skipping groups which do not have even a single data, though this condition should never be reached\n",
        "    if len(train_group) == 0 or len(val_group) == 0 or len(test_group) == 0:\n",
        "        print(\"Skipping due to insufficient data.\")\n",
        "        continue\n",
        "\n",
        "    # Applying preprocessing on each split\n",
        "    X_train, y_train = preprocess_group(train_group)\n",
        "    X_val, y_val = preprocess_group(val_group)\n",
        "    X_test, y_test_log = preprocess_group(test_group)\n",
        "\n",
        "    # Training and model building\n",
        "    # Increasing epochs from 30 to 80, as validation accuracy performs little better again after 50 epochs as seen while experimenting\n",
        "    model = build_transformer_model(input_shape=X_train.shape[1:])\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=80,\n",
        "        batch_size=32,\n",
        "        verbose=0,\n",
        "        callbacks=[keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]\n",
        "    )\n",
        "\n",
        "    model_path = f'/content/models/model_n{n}_k{k}_m{m}.h5'\n",
        "    model.save(model_path)\n",
        "    print(f\"Model saved to {model_path}\")\n",
        "\n",
        "    # Prediction on the test set\n",
        "    # Log base e value is predicted, which is converted to actual value\n",
        "    y_pred_log = model.predict(X_test).flatten()\n",
        "    y_pred = np.exp(y_pred_log)\n",
        "    y_true = np.exp(y_test_log)\n",
        "\n",
        "    # Clipping predictions to ensure valid domain for log2\n",
        "    y_pred = np.maximum(y_pred, 1.0)\n",
        "    y_true = np.maximum(y_true, 1.0)\n",
        "\n",
        "    # Computing RMSLE in log base 2 space\n",
        "    # This is done as the test cost function in the project scope suggests so\n",
        "    y_pred_log2 = np.log2(y_pred)\n",
        "    y_true_log2 = np.log2(y_true)\n",
        "    rmsle = np.sqrt(mean_squared_log_error(y_true_log2, y_pred_log2))\n",
        "    results.append(((n, k, m), rmsle))\n",
        "    print(f\"RMSLE (log base 2): {rmsle:.4f}\")\n",
        "\n",
        "print(\"\\n=== Summary of Results ===\")\n",
        "for (n, k, m), rmsle in results:\n",
        "    print(f\"Group (n={n}, k={k}, m={m}): RMSLE (log base 2) = {rmsle:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model is trained over 80 epochs rather than 30 epochs as in earlier submissions. Earlier I had only experimented till 50 epochs, and saw that validation loss was not decreasing after approximtely 30. But further experimentation showed that loss was again decreasing after 65 and converging near 80. Thus I finally came up with the above model."
      ],
      "metadata": {
        "id": "zQaIT2zciFEB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X63t2zDzMBmX"
      },
      "source": [
        "Next I generated another dataset of 100k rows, to further check how the model is performing on completely unseen data, and data that has been generated in a different session. This dataset was saved in my drive with the name 'm_height_dataset_1k.pkl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3CWmDwaLR5W",
        "outputId": "4389341b-7630-48f2-febe-bdbd7a362a9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\n",
            "--- Predictions for Group (n=9, k=4, m=2) ---\n",
            "Sample 1: Actual = 194.03, Predicted = 167.92\n",
            "Sample 2: Actual = 175.25, Predicted = 123.55\n",
            "Sample 3: Actual = 152.03, Predicted = 162.49\n",
            "Sample 4: Actual = 176.14, Predicted = 162.44\n",
            "Sample 5: Actual = 183.21, Predicted = 164.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\n",
            "--- Predictions for Group (n=9, k=4, m=3) ---\n",
            "Sample 1: Actual = 210.28, Predicted = 262.85\n",
            "Sample 2: Actual = 177.91, Predicted = 240.23\n",
            "Sample 3: Actual = 220.43, Predicted = 278.38\n",
            "Sample 4: Actual = 252.63, Predicted = 266.35\n",
            "Sample 5: Actual = 215.02, Predicted = 276.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "--- Predictions for Group (n=9, k=4, m=4) ---\n",
            "Sample 1: Actual = 3134.83, Predicted = 906.64\n",
            "Sample 2: Actual = 1434.17, Predicted = 1001.30\n",
            "Sample 3: Actual = 1550.49, Predicted = 913.07\n",
            "Sample 4: Actual = 1109.48, Predicted = 945.98\n",
            "Sample 5: Actual = 684.32, Predicted = 931.54\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\n",
            "--- Predictions for Group (n=9, k=4, m=5) ---\n",
            "Sample 1: Actual = 152304.11, Predicted = 23641.25\n",
            "Sample 2: Actual = 17305.33, Predicted = 23438.11\n",
            "Sample 3: Actual = 8202.88, Predicted = 23877.78\n",
            "Sample 4: Actual = 32600.17, Predicted = 27123.62\n",
            "Sample 5: Actual = 20170.64, Predicted = 24692.74\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\n",
            "--- Predictions for Group (n=9, k=5, m=2) ---\n",
            "Sample 1: Actual = 309.63, Predicted = 305.62\n",
            "Sample 2: Actual = 469.47, Predicted = 316.68\n",
            "Sample 3: Actual = 403.88, Predicted = 315.38\n",
            "Sample 4: Actual = 386.85, Predicted = 298.82\n",
            "Sample 5: Actual = 388.77, Predicted = 322.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\n",
            "--- Predictions for Group (n=9, k=5, m=3) ---\n",
            "Sample 1: Actual = 978.70, Predicted = 1019.35\n",
            "Sample 2: Actual = 960.01, Predicted = 1272.76\n",
            "Sample 3: Actual = 1099.08, Predicted = 1112.95\n",
            "Sample 4: Actual = 868.14, Predicted = 1555.80\n",
            "Sample 5: Actual = 511.28, Predicted = 1199.97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\n",
            "--- Predictions for Group (n=9, k=5, m=4) ---\n",
            "Sample 1: Actual = 2564955.57, Predicted = 30582.79\n",
            "Sample 2: Actual = 93582.35, Predicted = 33000.75\n",
            "Sample 3: Actual = 167199.64, Predicted = 32582.73\n",
            "Sample 4: Actual = 20684.01, Predicted = 30662.72\n",
            "Sample 5: Actual = 28919.13, Predicted = 24961.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\n",
            "--- Predictions for Group (n=9, k=6, m=2) ---\n",
            "Sample 1: Actual = 525.49, Predicted = 695.66\n",
            "Sample 2: Actual = 471.29, Predicted = 791.74\n",
            "Sample 3: Actual = 434.34, Predicted = 622.97\n",
            "Sample 4: Actual = 587.23, Predicted = 629.42\n",
            "Sample 5: Actual = 911.90, Predicted = 759.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\n",
            "--- Predictions for Group (n=9, k=6, m=3) ---\n",
            "Sample 1: Actual = 29425.84, Predicted = 19425.82\n",
            "Sample 2: Actual = 6838.80, Predicted = 19857.34\n",
            "Sample 3: Actual = 5219.96, Predicted = 18310.61\n",
            "Sample 4: Actual = 28336.84, Predicted = 18667.55\n",
            "Sample 5: Actual = 71185.12, Predicted = 19519.19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\n",
            "--- Predictions for Group (n=10, k=4, m=2) ---\n",
            "Sample 1: Actual = 14.81, Predicted = 55.82\n",
            "Sample 2: Actual = 103.84, Predicted = 57.40\n",
            "Sample 3: Actual = 126.22, Predicted = 56.13\n",
            "Sample 4: Actual = 120.04, Predicted = 64.31\n",
            "Sample 5: Actual = 112.29, Predicted = 62.02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\n",
            "--- Predictions for Group (n=10, k=4, m=3) ---\n",
            "Sample 1: Actual = 180.68, Predicted = 176.29\n",
            "Sample 2: Actual = 103.32, Predicted = 141.31\n",
            "Sample 3: Actual = 151.41, Predicted = 171.91\n",
            "Sample 4: Actual = 181.67, Predicted = 173.15\n",
            "Sample 5: Actual = 194.50, Predicted = 174.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "--- Predictions for Group (n=10, k=4, m=4) ---\n",
            "Sample 1: Actual = 590.14, Predicted = 328.57\n",
            "Sample 2: Actual = 402.80, Predicted = 339.41\n",
            "Sample 3: Actual = 233.70, Predicted = 345.02\n",
            "Sample 4: Actual = 207.79, Predicted = 346.45\n",
            "Sample 5: Actual = 228.45, Predicted = 336.85\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "--- Predictions for Group (n=10, k=4, m=5) ---\n",
            "Sample 1: Actual = 2226.66, Predicted = 1333.21\n",
            "Sample 2: Actual = 868.86, Predicted = 1368.02\n",
            "Sample 3: Actual = 615.25, Predicted = 1394.03\n",
            "Sample 4: Actual = 6058.14, Predicted = 1352.46\n",
            "Sample 5: Actual = 833.53, Predicted = 1307.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "--- Predictions for Group (n=10, k=4, m=6) ---\n",
            "Sample 1: Actual = 26225.24, Predicted = 45911.00\n",
            "Sample 2: Actual = 61018.48, Predicted = 38873.52\n",
            "Sample 3: Actual = 16677.29, Predicted = 46147.51\n",
            "Sample 4: Actual = 34827.39, Predicted = 34512.10\n",
            "Sample 5: Actual = 103531.57, Predicted = 39448.57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "--- Predictions for Group (n=10, k=5, m=2) ---\n",
            "Sample 1: Actual = 175.19, Predicted = 248.47\n",
            "Sample 2: Actual = 226.14, Predicted = 242.13\n",
            "Sample 3: Actual = 221.82, Predicted = 227.76\n",
            "Sample 4: Actual = 311.82, Predicted = 241.39\n",
            "Sample 5: Actual = 165.30, Predicted = 186.37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "--- Predictions for Group (n=10, k=5, m=3) ---\n",
            "Sample 1: Actual = 1502.48, Predicted = 443.31\n",
            "Sample 2: Actual = 460.90, Predicted = 425.93\n",
            "Sample 3: Actual = 370.51, Predicted = 460.68\n",
            "Sample 4: Actual = 440.30, Predicted = 453.29\n",
            "Sample 5: Actual = 633.06, Predicted = 461.51\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "--- Predictions for Group (n=10, k=5, m=4) ---\n",
            "Sample 1: Actual = 3283.15, Predicted = 2038.50\n",
            "Sample 2: Actual = 1513.29, Predicted = 1961.28\n",
            "Sample 3: Actual = 3004.40, Predicted = 2022.57\n",
            "Sample 4: Actual = 5171.45, Predicted = 1970.75\n",
            "Sample 5: Actual = 1494.52, Predicted = 1986.07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "--- Predictions for Group (n=10, k=5, m=5) ---\n",
            "Sample 1: Actual = 177047.48, Predicted = 73448.66\n",
            "Sample 2: Actual = 246821.81, Predicted = 62059.19\n",
            "Sample 3: Actual = 23983.40, Predicted = 73319.95\n",
            "Sample 4: Actual = 29059.81, Predicted = 61583.29\n",
            "Sample 5: Actual = 41024.03, Predicted = 70926.96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\n",
            "--- Predictions for Group (n=10, k=6, m=2) ---\n",
            "Sample 1: Actual = 738.55, Predicted = 429.65\n",
            "Sample 2: Actual = 413.91, Predicted = 465.36\n",
            "Sample 3: Actual = 285.07, Predicted = 435.67\n",
            "Sample 4: Actual = 1027.39, Predicted = 412.63\n",
            "Sample 5: Actual = 874.60, Predicted = 454.37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\n",
            "--- Predictions for Group (n=10, k=6, m=3) ---\n",
            "Sample 1: Actual = 1619.49, Predicted = 1733.02\n",
            "Sample 2: Actual = 1884.39, Predicted = 1730.80\n",
            "Sample 3: Actual = 1319.60, Predicted = 1745.96\n",
            "Sample 4: Actual = 1010.55, Predicted = 1873.62\n",
            "Sample 5: Actual = 4016.91, Predicted = 1856.90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\n",
            "--- Predictions for Group (n=10, k=6, m=4) ---\n",
            "Sample 1: Actual = 137656.18, Predicted = 61240.79\n",
            "Sample 2: Actual = 40116.68, Predicted = 65626.51\n",
            "Sample 3: Actual = 31498.34, Predicted = 59551.20\n",
            "Sample 4: Actual = 485405.97, Predicted = 67428.75\n",
            "Sample 5: Actual = 246626.37, Predicted = 64087.20\n",
            "\n",
            "=== Global Test Evaluation ===\n",
            "Total Samples: 100000\n",
            "Global Average Cost σ: 1.4455\n",
            "Global RMSLE (log base 2): 0.0851\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "from zipfile import ZipFile\n",
        "from google.colab import drive\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "\n",
        "'''\n",
        "  Usual preprocessing done before too while training\n",
        "'''\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "test_file_path = '/content/drive/My Drive/m_height_100k.pkl'\n",
        "with open(test_file_path, 'rb') as f:\n",
        "    test_df = joblib.load(f)\n",
        "\n",
        "\n",
        "# Fixing max_k based on analysis during training\n",
        "max_k = 6\n",
        "\n",
        "\n",
        "def preprocess_group(group_df):\n",
        "    X_list, y_list = [], []\n",
        "    for _, row in group_df.iterrows():\n",
        "        P = np.array(row['P']).astype(np.float32)\n",
        "        n, k, m = row['n'], row['k'], row['m']\n",
        "        meta = np.array([n, k, m], dtype=np.float32)\n",
        "\n",
        "        row_features = []\n",
        "        for i in range(P.shape[0]):\n",
        "            pos_encoding = np.zeros(max_k)\n",
        "            pos_encoding[i] = 1.0\n",
        "            features = np.concatenate([P[i], meta, pos_encoding])\n",
        "            row_features.append(features)\n",
        "\n",
        "        X = np.array(row_features)\n",
        "        X_list.append(X)\n",
        "        y_list.append(np.log(row['h_m_C']))\n",
        "    return np.array(X_list), np.array(y_list)\n",
        "\n",
        "'''\n",
        "  The final model was saved with the name '436000715_models_3.zip'.\n",
        "  That is now uploaded to runtime and unzipped.\n",
        "  The test data is first grouped into bins of each combinations\n",
        "  of (n, k, m), and then the pertaining model is invoked.\n",
        "'''\n",
        "model_zip_path = '436000715_models_3.zip'\n",
        "model_dir = 'models'\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "with ZipFile(model_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(model_dir)\n",
        "\n",
        "# These variables keep track of the evaluation metrics, globally across all models\n",
        "all_preds_log2 = []\n",
        "all_trues_log2 = []\n",
        "\n",
        "custom_objects = {'mse': keras.losses.MeanSquaredError()}\n",
        "# Splitting data into groups\n",
        "unique_groups = sorted(test_df.groupby(['n', 'k', 'm']).groups.keys())\n",
        "\n",
        "for (n, k, m) in unique_groups:\n",
        "    model_path = os.path.join(model_dir, f\"model_n{n}_k{k}_m{m}.h5\")\n",
        "    #This condition should not be reached, but an error check\n",
        "    if not os.path.exists(model_path):\n",
        "        continue\n",
        "\n",
        "    group_df = test_df[(test_df['n'] == n) & (test_df['k'] == k) & (test_df['m'] == m)]\n",
        "    if len(group_df) == 0:\n",
        "        continue\n",
        "\n",
        "    X_test, y_test_log = preprocess_group(group_df)\n",
        "    model = keras.models.load_model(model_path, custom_objects=custom_objects)\n",
        "\n",
        "    y_pred_log = model.predict(X_test).flatten()\n",
        "    y_pred = np.exp(y_pred_log)\n",
        "    y_true = np.exp(y_test_log)\n",
        "\n",
        "    y_pred = np.maximum(y_pred, 1.0)\n",
        "    y_true = np.maximum(y_true, 1.0)\n",
        "\n",
        "    all_preds_log2.extend(np.log2(y_pred))\n",
        "    all_trues_log2.extend(np.log2(y_true))\n",
        "\n",
        "    # To check the results, printing some actual vs predicted m-heights\n",
        "    print(f\"\\n--- Predictions for Group (n={n}, k={k}, m={m}) ---\")\n",
        "    num_samples = min(len(y_true), 5)\n",
        "    for i in range(num_samples):\n",
        "        print(f\"Sample {i+1}: Actual = {y_true[i]:.2f}, Predicted = {y_pred[i]:.2f}\")\n",
        "\n",
        "# Calculating all the metrics globally\n",
        "if all_preds_log2:\n",
        "    all_preds_log2 = np.array(all_preds_log2)\n",
        "    all_trues_log2 = np.array(all_trues_log2)\n",
        "\n",
        "    global_rmsle = np.sqrt(mean_squared_log_error(all_trues_log2, all_preds_log2))\n",
        "    avg_cost = np.mean((all_trues_log2 - all_preds_log2) ** 2)\n",
        "\n",
        "    print(\"\\n=== Global Test Evaluation ===\")\n",
        "    print(f\"Total Samples: {len(all_preds_log2)}\")\n",
        "    print(f\"Global Average Cost σ: {avg_cost:.4f}\")\n",
        "    print(f\"Global RMSLE (log base 2): {global_rmsle:.4f}\")\n",
        "else:\n",
        "    print(\"No valid predictions found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zX1ztJiDnRO"
      },
      "source": [
        "The next cell runs the evaluation on the test set. As said in the project scope, upload the models directory shared, named, '436000715_models.zip'.\n",
        "The function call has been done. Just update the dictionary 'inputs', to your evaluation dictionary. The format has been followed as in the template. Next, the cell returns a dictionary as output, and prints it.\n",
        "\n",
        "After inserting your input in the placeholder, and uploading the zip file, run the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gy7eJZZq08HO",
        "outputId": "d01ef256-ade5-47ec-beb4-b94c25b4bc40"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Outputs ===\n",
            "[9,6,3] => [4725.53173828125]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "from zipfile import ZipFile\n",
        "from google.colab import drive\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "\n",
        "def predict_m_heights(inputs, model_dir, max_k=6):\n",
        "    outputs = {}\n",
        "    custom_objects = {'mse': keras.losses.MeanSquaredError()}\n",
        "\n",
        "    for key, matrices in inputs.items():\n",
        "        # Extracting n, k, m from the dictionary\n",
        "        n, k, m = eval(key)\n",
        "        model_path = os.path.join(model_dir, f\"model_n{n}_k{k}_m{m}.h5\")\n",
        "\n",
        "        # Skipping, in case model is not found\n",
        "        if not os.path.exists(model_path):\n",
        "            print(f\"Model for group (n={n}, k={k}, m={m}) not found.\")\n",
        "            continue\n",
        "\n",
        "        # Loading the model here\n",
        "        model = keras.models.load_model(model_path, custom_objects=custom_objects)\n",
        "        preds = []\n",
        "\n",
        "        # Preprocessing the P_list\n",
        "        for P in matrices:\n",
        "            P = np.array(P).astype(np.float32)\n",
        "            meta = np.array([n, k, m], dtype=np.float32)\n",
        "\n",
        "            row_features = []\n",
        "            for i in range(P.shape[0]):\n",
        "                pos_encoding = np.zeros(max_k)\n",
        "                pos_encoding[i] = 1.0\n",
        "                features = np.concatenate([P[i], meta, pos_encoding])\n",
        "                row_features.append(features)\n",
        "\n",
        "            X = np.array([row_features])\n",
        "            y_pred_log = model.predict(X, verbose=0).flatten()[0]\n",
        "            y_pred = np.exp(y_pred_log)\n",
        "            y_pred = max(1.0, y_pred)\n",
        "            preds.append(y_pred)\n",
        "\n",
        "        outputs[key] = preds\n",
        "\n",
        "    return outputs\n",
        "\n",
        "\n",
        "# Sample input is shown, modify the input with test set here\n",
        "'''\n",
        "inputs = {\n",
        "    '[9,6,3]': [\n",
        "        np.array([\n",
        "            [ 0.4759809,  0.9938236, 0.819425 ],\n",
        "            [-0.8960798, -0.7442706, 0.3345122],\n",
        "            [ 0.4759809,  0.9938236, 0.819425 ],\n",
        "            [-0.8960798, -0.7442706, 0.3345122],\n",
        "            [ 0.4759809,  0.9938236, 0.819425 ],\n",
        "            [-0.8960798, -0.7442706, 0.3345122],\n",
        "        ]),\n",
        "        # Add more P matrices here if needed\n",
        "\n",
        "    ],\n",
        "}\n",
        "'''\n",
        "# Insert here\n",
        "inputs = {\n",
        "\n",
        "}\n",
        "\n",
        "model_zip_path = '436000715_models_3.zip'\n",
        "model_dir = 'models'\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "with ZipFile(model_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(model_dir)\n",
        "\n",
        "# Calling the required function here\n",
        "outputs = predict_m_heights(inputs, model_dir, max_k=6)\n",
        "\n",
        "print(\"\\n=== Outputs ===\")\n",
        "for key in outputs:\n",
        "    preds = [float(x) for x in outputs[key]]\n",
        "    print(f\"{key} => {preds}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}