{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This dataset generation code is written using the hints given in the project scope document, and the proof from the reference paper attached along."
      ],
      "metadata": {
        "id": "7fnUuzWWnLKy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bB9Tb_573OUx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9d98da5-a660-43ec-e948-4910b622eec6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/21] Computed h_m(C) for (n=9, k=4, m=2) -> 144.90346620425922\n",
            "[2/21] Computed h_m(C) for (n=9, k=4, m=3) -> 242.89075886905553\n",
            "[3/21] Computed h_m(C) for (n=9, k=4, m=4) -> 1330.2166227995049\n",
            "[4/21] Computed h_m(C) for (n=9, k=4, m=5) -> 4086.4253934219873\n",
            "[5/21] Computed h_m(C) for (n=9, k=5, m=2) -> 321.2006862406292\n",
            "[6/21] Computed h_m(C) for (n=9, k=5, m=3) -> 884.4806452981419\n",
            "[7/21] Computed h_m(C) for (n=9, k=5, m=4) -> 10349.177498422843\n",
            "[8/21] Computed h_m(C) for (n=9, k=6, m=2) -> 898.8751718194876\n",
            "[9/21] Computed h_m(C) for (n=9, k=6, m=3) -> 39566.99255978265\n",
            "[10/21] Computed h_m(C) for (n=10, k=4, m=2) -> 142.99082974010506\n",
            "[11/21] Computed h_m(C) for (n=10, k=4, m=3) -> 158.20899105501928\n",
            "[12/21] Computed h_m(C) for (n=10, k=4, m=4) -> 325.48136135587765\n",
            "[13/21] Computed h_m(C) for (n=10, k=4, m=5) -> 3390.269358512461\n",
            "[14/21] Computed h_m(C) for (n=10, k=4, m=6) -> 64123.66800799458\n",
            "[15/21] Computed h_m(C) for (n=10, k=5, m=2) -> 178.21142924308538\n",
            "[16/21] Computed h_m(C) for (n=10, k=5, m=3) -> 396.26188019848735\n",
            "[17/21] Computed h_m(C) for (n=10, k=5, m=4) -> 3470.7757817283864\n",
            "[18/21] Computed h_m(C) for (n=10, k=5, m=5) -> 8392.361996381358\n",
            "[19/21] Computed h_m(C) for (n=10, k=6, m=2) -> 340.0818600054959\n",
            "[20/21] Computed h_m(C) for (n=10, k=6, m=3) -> 2559.1273103716985\n",
            "[21/21] Computed h_m(C) for (n=10, k=6, m=4) -> 78346.40252421839\n",
            "Dataset saved successfully!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from scipy.optimize import linprog\n",
        "\n",
        "'''\n",
        "This function is used to compute m-height and generate the dataset\n",
        "The code here just checks if it is working fine for each combination of (n, k, m)\n",
        "As this optimization takes GPU operations, to generate data for 1M, a modified version of this code was run on HPRC\n",
        "'''\n",
        "\n",
        "def m_height_linprog_exact(P, n, k, m):\n",
        "\n",
        "    # Constructing generator matrix G = [I_k | P]\n",
        "    G = np.hstack((np.eye(k), P))\n",
        "    indices = list(range(n))\n",
        "\n",
        "    # All the possible psi vectors of length m with their entries ±1\n",
        "    psi_set = list(itertools.product([-1, 1], repeat=m))\n",
        "\n",
        "    # This is the max m-height value, initially 0\n",
        "    h_m_C = 0\n",
        "\n",
        "\n",
        "    '''\n",
        "    This nested function is used to solve the LP optimization of m-height for\n",
        "    a fixed (a, b, X, psi)\n",
        "    '''\n",
        "\n",
        "    def solve_LP(a, b, X, psi):\n",
        "\n",
        "        # Y is the set of remaining coordinates which are not in X, a, or b\n",
        "        Y = list(set(indices) - set(X) - {a, b})\n",
        "\n",
        "        # For psi index mapping, order of coordinates is: a, X, Y, b\n",
        "        thou = [a] + sorted(list(X)) + Y + [b]\n",
        "\n",
        "        # Objective funcion is: maximize psi[0] * <G[:,a], v> where v is a vector in R^k\n",
        "        # Using -c here to reverse the objective, as linprog minimizes\n",
        "        c = np.array([psi[0] * G[i, a] for i in range(k)])\n",
        "\n",
        "        # The inequality constraints\n",
        "        A_ub, b_ub = [], []\n",
        "\n",
        "        # Following are the constraints for j in X\n",
        "        for j in X:\n",
        "            # first\n",
        "            A_ub.append([psi[thou.index(j)] * G[i, j] - psi[0] * G[i, a] for i in range(k)])\n",
        "            b_ub.append(0)\n",
        "            # second\n",
        "            A_ub.append([-psi[thou.index(j)] * G[i, j] for i in range(k)])\n",
        "            b_ub.append(-1)\n",
        "\n",
        "        # Following are the constraints for j in Y\n",
        "        for j in Y:\n",
        "            #The bound is: |<G[:,j], v>| <=1\n",
        "            A_ub.append([G[i, j] for i in range(k)])\n",
        "            b_ub.append(1)\n",
        "            A_ub.append([-G[i, j] for i in range(k)])\n",
        "            b_ub.append(1)\n",
        "\n",
        "        # Equality constraint: <G[:,b], v> =1\n",
        "        A_eq = [[G[i, b] for i in range(k)]]\n",
        "        b_eq = [1]\n",
        "\n",
        "        bounds = [(None, None)] * k\n",
        "        res = linprog(-c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')\n",
        "\n",
        "        # If success then return the optimal value, else return 0\n",
        "        return -res.fun if res.success else 0\n",
        "\n",
        "    # Going over all the valid pairs (a, b)\n",
        "    for a, b in itertools.permutations(indices, 2):\n",
        "        # Going over all (m-1)-size subsets X excluding a, b\n",
        "        for X in itertools.combinations(set(indices) - {a, b}, m - 1):\n",
        "            # Going over all ±1 vectors of length m\n",
        "            for psi in psi_set:\n",
        "                z_val = solve_LP(a, b, X, psi)\n",
        "                # Always storing the maximum height so far.\n",
        "                h_m_C = max(h_m_C, z_val)\n",
        "    return h_m_C\n",
        "\n",
        "# List of 21 (n, k, m) combinations in the project scope\n",
        "combinations = [\n",
        "    (9, 4, 2), (9, 4, 3), (9, 4, 4), (9, 4, 5), (9, 5, 2), (9, 5, 3), (9, 5, 4),\n",
        "    (9, 6, 2), (9, 6, 3), (10, 4, 2), (10, 4, 3), (10, 4, 4), (10, 4, 5), (10, 4, 6),\n",
        "    (10, 5, 2), (10, 5, 3), (10, 5, 4), (10, 5, 5), (10, 6, 2), (10, 6, 3), (10, 6, 4)\n",
        "]\n",
        "\n",
        "# Generating and storing data\n",
        "data = []\n",
        "for i, (n, k, m) in enumerate(combinations, 1):\n",
        "    # P part of the G matrix is generated and value of P ranges between [-100,100]\n",
        "    P = np.random.uniform(-100, 100, size=(k, n - k))\n",
        "    h_m_C = m_height_linprog_exact(P, n, k, m)\n",
        "    data.append((n, k, m, h_m_C, P))\n",
        "    print(f\"[{i}/{len(combinations)}] Computed h_m(C) for (n={n}, k={k}, m={m}) -> {h_m_C}\")\n",
        "\n",
        "# Saving as a DataFrame\n",
        "df = pd.DataFrame(data, columns=['n', 'k', 'm', 'h_m_C', 'P'])\n",
        "df.to_pickle(\"m_height_dataset.pkl\")\n",
        "print(\"Dataset saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from scipy.optimize import linprog\n",
        "import os\n",
        "import joblib\n",
        "\n",
        "'''\n",
        "This function is used to compute m-height and generate the dataset\n",
        "The code runs 47619 time per combination to generate the dataset.\n",
        "This was run on HPRC using a SLURM job.\n",
        "'''\n",
        "\n",
        "def m_height_linprog_exact(P, n, k, m):\n",
        "\n",
        "    # Constructing generator matrix G = [I_k | P]\n",
        "    G = np.hstack((np.eye(k), P))\n",
        "    indices = list(range(n))\n",
        "\n",
        "    # All the possible psi vectors of length m with their entries ±1\n",
        "    psi_set = list(itertools.product([-1, 1], repeat=m))\n",
        "\n",
        "    # This is the max m-height value, initially 0\n",
        "    h_m_C = 0\n",
        "\n",
        "\n",
        "    '''\n",
        "    This nested function is used to solve the LP optimization of m-height for\n",
        "    a fixed (a, b, X, psi)\n",
        "    '''\n",
        "\n",
        "    def solve_LP(a, b, X, psi):\n",
        "\n",
        "        # Y is the set of remaining coordinates which are not in X, a, or b\n",
        "        Y = list(set(indices) - set(X) - {a, b})\n",
        "\n",
        "        # For psi index mapping, order of coordinates is: a, X, Y, b\n",
        "        thou = [a] + sorted(list(X)) + Y + [b]\n",
        "\n",
        "        # Objective funcion is: maximize psi[0] * <G[:,a], v> where v is a vector in R^k\n",
        "        # Using -c here to reverse the objective, as linprog minimizes\n",
        "        c = np.array([psi[0] * G[i, a] for i in range(k)])\n",
        "\n",
        "        # The inequality constraints\n",
        "        A_ub, b_ub = [], []\n",
        "\n",
        "        # Following are the constraints for j in X\n",
        "        for j in X:\n",
        "            # first\n",
        "            A_ub.append([psi[thou.index(j)] * G[i, j] - psi[0] * G[i, a] for i in range(k)])\n",
        "            b_ub.append(0)\n",
        "            # second\n",
        "            A_ub.append([-psi[thou.index(j)] * G[i, j] for i in range(k)])\n",
        "            b_ub.append(-1)\n",
        "\n",
        "        # Following are the constraints for j in Y\n",
        "        for j in Y:\n",
        "            #The bound is: |<G[:,j], v>| <=1\n",
        "            A_ub.append([G[i, j] for i in range(k)])\n",
        "            b_ub.append(1)\n",
        "            A_ub.append([-G[i, j] for i in range(k)])\n",
        "            b_ub.append(1)\n",
        "\n",
        "        # Equality constraint: <G[:,b], v> =1\n",
        "        A_eq = [[G[i, b] for i in range(k)]]\n",
        "        b_eq = [1]\n",
        "\n",
        "        bounds = [(None, None)] * k\n",
        "        res = linprog(-c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')\n",
        "\n",
        "        # If success then return the optimal value, else return\n",
        "        return -res.fun if res.success else 0\n",
        "\n",
        "    # Going over all the valid pairs (a, b)\n",
        "    for a, b in itertools.permutations(indices, 2):\n",
        "        # Going over all (m-1)-size subsets X excluding a, b\n",
        "        for X in itertools.combinations(set(indices) - {a, b}, m - 1):\n",
        "            # Going over all ±1 vectors of length m\n",
        "            for psi in psi_set:\n",
        "                z_val = solve_LP(a, b, X, psi)\n",
        "                # Always storing the maximum height so far.\n",
        "                h_m_C = max(h_m_C, z_val)\n",
        "    return h_m_C\n",
        "\n",
        "# List of 21 (n, k, m) combinations in the project scope\n",
        "combinations = [\n",
        "    (9, 4, 2), (9, 4, 3), (9, 4, 4), (9, 4, 5), (9, 5, 2), (9, 5, 3), (9, 5, 4),\n",
        "    (9, 6, 2), (9, 6, 3), (10, 4, 2), (10, 4, 3), (10, 4, 4), (10, 4, 5), (10, 4, 6),\n",
        "    (10, 5, 2), (10, 5, 3), (10, 5, 4), (10, 5, 5), (10, 6, 2), (10, 6, 3), (10, 6, 4)\n",
        "]\n",
        "\n",
        "# Generating and storing data\n",
        "data = []\n",
        "\n",
        "# Generating euqual number of samples for each combiation to get ~1M data\n",
        "samples_per_combination = 47619\n",
        "\n",
        "for i, (n, k, m) in enumerate(combinations, 1):\n",
        "    for j in range(samples_per_combination):\n",
        "        # P part of the G matrix is generated and value of P ranges between [-100,100]\n",
        "        P = np.random.uniform(-100, 100, size=(k, n - k))\n",
        "        h_m_C = m_height_linprog_exact(P, n, k, m)\n",
        "        data.append((n, k, m, h_m_C, P))\n",
        "        # print(f\"[{i}/{len(combinations)}] Computed h_m(C) for (n={n}, k={k}, m={m}) -> {h_m_C}\")\n",
        "\n",
        "# Saving as a DataFrame in my directory\n",
        "df = pd.DataFrame(data, columns=['n', 'k', 'm', 'h_m_C', 'P'])\n",
        "output_dir = os.environ.get(\"SCRATCH\") + \"/dipanwita22rano/dlproject\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "output_path = os.path.join(output_dir, \"m_height_dataset.pkl\")\n",
        "with open(output_path, 'wb') as f:\n",
        "    joblib.dump(df, f)\n",
        "print(\"Dataset saved successfully!\")\n"
      ],
      "metadata": {
        "id": "8HVCJDfBEn_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/My Drive/m_height_dataset.pkl'\n",
        "with open(file_path, 'rb') as f:\n",
        "    df = joblib.load(f)\n",
        "\n",
        "'''\n",
        "  I had shuffled the dataset using this code, so that when I had made a single\n",
        "  feed forward model, it sees random data, not similar data in sequence.\n",
        "'''\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "output_path = '/content/drive/My Drive/m_height_dataset_.pkl'\n",
        "with open(output_path, 'wb') as f:\n",
        "    joblib.dump(df, f)\n",
        "print(df.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKlrPKCKMX0I",
        "outputId": "c608cbb5-85e7-4bb2-9760-e77eb27df67c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "    n  k  m         h_m_C                                                  P\n",
            "0  10  4  3    180.681884  [[0.41332842078512044, 70.03763016732799, 92.9...\n",
            "1   9  6  3  29425.835225  [[-22.39439891822049, -45.59568035361643, 84.5...\n",
            "2  10  4  4    590.143407  [[-98.04865191290197, 55.176558968450024, -47....\n",
            "3   9  6  3   6838.797140  [[-72.01756032528372, -96.84222090558315, -97....\n",
            "4   9  6  3   5219.964621  [[86.98714113704173, 62.11282763418615, -49.67...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experimenting on LSTM + Bi-Encoder Model.\n",
        "* As the order of rows in P does not hold semantic meaning, LSTMs can still try to extract relational patterns between rows that may influence the m-height through learned temporal dependencies.\n",
        "* The Bidirectional LSTM acts as a bi-encoder by processing the matrix in both forward and backward directions. This should allow the model to encode contextual information from all surrounding rows, improving the representation of each row in relation to the others. This is especially helpful sine h_m_C may depend on global row interactions rather than isolated patterns.\n",
        "* The metadata encoder should capture the structural information about the code, and its fusion with the LSTM output provides a joint representation of both the code matrix and its configuration.\n",
        "This bi-encoder setup should help the model learn richer, more expressive features that generalize better across varying group structures.\n",
        "\n",
        "But the experimenation results prove othrwise. The average test cost on the same dataset is worse than the transformer based model. This means the LSTM model stores history, which is not something needed for m-height problem."
      ],
      "metadata": {
        "id": "_Z56PJHgclLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from tensorflow import keras\n",
        "from keras import layers, regularizers\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/My Drive/m_height_dataset.pkl'\n",
        "with open(file_path, 'rb') as f:\n",
        "    df = joblib.load(f)\n",
        "\n",
        "df['k_val'] = df['P'].apply(lambda x: x.shape[0])\n",
        "max_k = df['k_val'].max()\n",
        "print(f\"Maximum k (rows in P): {max_k}\")\n",
        "\n",
        "train_val_df, test_df = train_test_split(df, test_size=0.15, random_state=42)\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.15, random_state=42)\n",
        "\n",
        "def preprocess_group_lstm(group_df):\n",
        "    X_list, y_list = [], []\n",
        "    for _, row in group_df.iterrows():\n",
        "        P = np.array(row['P']).astype(np.float32)\n",
        "        n, k, m = row['n'], row['k'], row['m']\n",
        "        meta = np.array([n, k, m], dtype=np.float32)\n",
        "\n",
        "        padded_P = np.zeros((max_k, P.shape[1]), dtype=np.float32)\n",
        "        padded_P[:P.shape[0], :] = P\n",
        "\n",
        "        X_list.append((padded_P, meta))\n",
        "        y_list.append(np.log2(row['h_m_C']))\n",
        "    return X_list, np.array(y_list)\n",
        "\n",
        "\n",
        "'''\n",
        "  LSTM + Bi-Encoder Architecture\n",
        "'''\n",
        "\n",
        "def build_lstm_model(P_dim, meta_dim):\n",
        "    P_input = keras.Input(shape=(max_k, P_dim), name='P_input')\n",
        "    meta_input = keras.Input(shape=(meta_dim,), name='meta_input')\n",
        "\n",
        "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(P_input)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "    combined = layers.Concatenate()([x, meta_input])\n",
        "    combined = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(combined)\n",
        "    combined = layers.Dropout(0.3)(combined)\n",
        "    combined = layers.Dense(64, activation='relu')(combined)\n",
        "    output = layers.Dense(1)(combined)\n",
        "\n",
        "    model = keras.Model(inputs=[P_input, meta_input], outputs=output)\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "\n",
        "os.makedirs('/content/models_lstm', exist_ok=True)\n",
        "\n",
        "all_y_true_log2 = []\n",
        "all_y_pred_log2 = []\n",
        "\n",
        "unique_groups = sorted(train_df.groupby(['n', 'k', 'm']).groups.keys())\n",
        "\n",
        "for (n, k, m) in unique_groups:\n",
        "    train_group = train_df[(train_df['n'] == n) & (train_df['k'] == k) & (train_df['m'] == m)]\n",
        "    val_group = val_df[(val_df['n'] == n) & (val_df['k'] == k) & (val_df['m'] == m)]\n",
        "    test_group = test_df[(test_df['n'] == n) & (test_df['k'] == k) & (test_df['m'] == m)]\n",
        "\n",
        "    if len(train_group) == 0 or len(val_group) == 0 or len(test_group) == 0:\n",
        "        continue\n",
        "\n",
        "    X_train_raw, y_train = preprocess_group_lstm(train_group)\n",
        "    X_val_raw, y_val = preprocess_group_lstm(val_group)\n",
        "    X_test_raw, y_test_log2 = preprocess_group_lstm(test_group)\n",
        "\n",
        "    X_train_P = np.array([x[0] for x in X_train_raw])\n",
        "    X_train_meta = np.array([x[1] for x in X_train_raw])\n",
        "    X_val_P = np.array([x[0] for x in X_val_raw])\n",
        "    X_val_meta = np.array([x[1] for x in X_val_raw])\n",
        "    X_test_P = np.array([x[0] for x in X_test_raw])\n",
        "    X_test_meta = np.array([x[1] for x in X_test_raw])\n",
        "\n",
        "    model = build_lstm_model(P_dim=X_train_P.shape[2], meta_dim=3)\n",
        "    model.fit(\n",
        "        {'P_input': X_train_P, 'meta_input': X_train_meta},\n",
        "        y_train,\n",
        "        validation_data=({'P_input': X_val_P, 'meta_input': X_val_meta}, y_val),\n",
        "        epochs=50,\n",
        "        batch_size=32,\n",
        "        verbose=0,\n",
        "        callbacks=[keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]\n",
        "    )\n",
        "\n",
        "    model_path = f'/content/models_lstm/model_n{n}_k{k}_m{m}.h5'\n",
        "    model.save(model_path)\n",
        "\n",
        "    y_pred_log2 = model.predict({'P_input': X_test_P, 'meta_input': X_test_meta}).flatten()\n",
        "    y_pred = np.power(2, y_pred_log2)\n",
        "    y_true = np.power(2, y_test_log2)\n",
        "\n",
        "    y_pred = np.maximum(y_pred, 1.0)\n",
        "    y_true = np.maximum(y_true, 1.0)\n",
        "\n",
        "    all_y_pred_log2.extend(np.log2(y_pred))\n",
        "    all_y_true_log2.extend(np.log2(y_true))\n",
        "\n",
        "\n",
        "if all_y_true_log2 and all_y_pred_log2:\n",
        "    all_y_true_log2 = np.array(all_y_true_log2)\n",
        "    all_y_pred_log2 = np.array(all_y_pred_log2)\n",
        "\n",
        "    rmsle = np.sqrt(mean_squared_log_error(all_y_true_log2, all_y_pred_log2))\n",
        "    test_cost = np.mean(np.square(all_y_true_log2 - all_y_pred_log2))\n",
        "\n",
        "    print(f\"\\nOverall RMSLE (log₂): {rmsle:.4f}\")\n",
        "    print(f\"Average test cost (log₂ squared error): {test_cost:.4f}\")\n",
        "else:\n",
        "    print(\"No valid predictions to evaluate.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7Ie1V-1cpuC",
        "outputId": "7dd782d3-61e3-4909-dfb7-624ecb00128c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Maximum k (rows in P): 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m394/394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\n",
            "Overall RMSLE (log₂): 0.1291\n",
            "Average test cost (log₂ squared error): 2.3536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experimenting on a Set Transformer Model:\n",
        "* It was chosen to better align with the nature of the generator matrix, which can be viewed as a set of row vectors.\n",
        "* Unlike LSTMs, which impose an order on the input, Set Transformers are permutation-invariant. (To experiment whether row ordering gives better results or without ordering.)\n",
        "* Each row of P is concatenated with metadata (n, k, m), which should allow the model to consider not just individual row characteristics, but also how each row cotributes in the context of the full code specification.\n",
        "* The multi-headed self-attention blocks should allow the model to learn pairwise interactions between rows which might enable it to model higher-order dependencies and relations that might contribute to the m-height.\n",
        "\n",
        "But, this experimentation showed to have the worst results. This means we need to have a sense of row-order structure maintenance in the architecture."
      ],
      "metadata": {
        "id": "gcAO0EaKxZci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from tensorflow import keras\n",
        "from keras import layers, regularizers\n",
        "import tensorflow as tf\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/My Drive/m_height_dataset.pkl'\n",
        "with open(file_path, 'rb') as f:\n",
        "    df = joblib.load(f)\n",
        "\n",
        "df['k_val'] = df['P'].apply(lambda x: x.shape[0])\n",
        "max_k = df['k_val'].max()\n",
        "print(f\"Maximum k (rows in P): {max_k}\")\n",
        "\n",
        "train_val_df, test_df = train_test_split(df, test_size=0.15, random_state=42)\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.15, random_state=42)\n",
        "\n",
        "# preprocessimg to be compatible with the set format\n",
        "def preprocess_group(group_df):\n",
        "    X_list, y_list = [], []\n",
        "    for _, row in group_df.iterrows():\n",
        "        P = np.array(row['P']).astype(np.float32)\n",
        "        n, k, m = row['n'], row['k'], row['m']\n",
        "        meta = np.array([n, k, m], dtype=np.float32)\n",
        "\n",
        "        row_features = []\n",
        "        for i in range(P.shape[0]):\n",
        "            features = np.concatenate([P[i], meta])\n",
        "            row_features.append(features)\n",
        "\n",
        "        # Zero padding\n",
        "        while len(row_features) < max_k:\n",
        "            row_features.append(np.zeros_like(row_features[0]))\n",
        "\n",
        "        X = np.array(row_features)\n",
        "        X_list.append(X)\n",
        "        y_list.append(np.log2(row['h_m_C']))\n",
        "    return np.array(X_list), np.array(y_list)\n",
        "\n",
        "'''\n",
        "  Set Transformer Architecture\n",
        "'''\n",
        "\n",
        "def build_set_transformer(input_shape):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    # 2 perumation invariant self attention blocks\n",
        "    x = layers.Dense(64, activation='relu')(inputs)\n",
        "    x = layers.MultiHeadAttention(num_heads=4, key_dim=16)(x, x)\n",
        "    x = layers.LayerNormalization()(x)\n",
        "    x = layers.MultiHeadAttention(num_heads=4, key_dim=16)(x, x)\n",
        "    x = layers.LayerNormalization()(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "    # MLP head\n",
        "    x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "    outputs = layers.Dense(1)(x)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "os.makedirs('/content/models', exist_ok=True)\n",
        "all_y_true_log2, all_y_pred_log2 = [], []\n",
        "\n",
        "unique_groups = sorted(train_df.groupby(['n', 'k', 'm']).groups.keys())\n",
        "\n",
        "for (n, k, m) in unique_groups:\n",
        "    train_group = train_df[(train_df['n'] == n) & (train_df['k'] == k) & (train_df['m'] == m)]\n",
        "    val_group = val_df[(val_df['n'] == n) & (val_df['k'] == k) & (val_df['m'] == m)]\n",
        "    test_group = test_df[(test_df['n'] == n) & (test_df['k'] == k) & (test_df['m'] == m)]\n",
        "\n",
        "    if len(train_group) == 0 or len(val_group) == 0 or len(test_group) == 0:\n",
        "        continue\n",
        "\n",
        "    X_train, y_train = preprocess_group(train_group)\n",
        "    X_val, y_val = preprocess_group(val_group)\n",
        "    X_test, y_test_log2 = preprocess_group(test_group)\n",
        "\n",
        "    model = build_set_transformer(input_shape=X_train.shape[1:])\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=30,\n",
        "        batch_size=32,\n",
        "        verbose=0,\n",
        "        callbacks=[keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]\n",
        "    )\n",
        "\n",
        "    model_path = f'/content/models/model_n{n}_k{k}_m{m}.h5'\n",
        "    model.save(model_path)\n",
        "\n",
        "    y_pred_log2 = model.predict(X_test).flatten()\n",
        "    y_pred = np.power(2, y_pred_log2)\n",
        "    y_true = np.power(2, y_test_log2)\n",
        "\n",
        "    y_pred = np.maximum(y_pred, 1.0)\n",
        "    y_true = np.maximum(y_true, 1.0)\n",
        "\n",
        "    all_y_pred_log2.extend(np.log2(y_pred))\n",
        "    all_y_true_log2.extend(np.log2(y_true))\n",
        "\n",
        "\n",
        "if all_y_true_log2 and all_y_pred_log2:\n",
        "    all_y_true_log2 = np.array(all_y_true_log2)\n",
        "    all_y_pred_log2 = np.array(all_y_pred_log2)\n",
        "\n",
        "    rmsle = np.sqrt(mean_squared_log_error(all_y_true_log2, all_y_pred_log2))\n",
        "    test_cost = np.mean(np.square(all_y_true_log2 - all_y_pred_log2))\n",
        "\n",
        "    print(f\"\\nFinal RMSLE (log₂): {rmsle:.4f}\")\n",
        "    print(f\"Average test cost (log₂ squared error): {test_cost:.4f}\")\n",
        "else:\n",
        "    print(\"No valid predictions to evaluate.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8AQGN5dmDFq",
        "outputId": "f424d6c8-ab8b-4f09-f890-6a7cf78cfe55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Maximum k (rows in P): 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m394/394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\n",
            "Final RMSLE (log₂): 0.1181\n",
            "Average test cost (log₂ squared error): 2.0712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the final model I came up with, with the lowest RMSLE amongst all other methods that i tried. This set of 21 models use transformer models, with one-hot encoding of row indices.\n",
        "\n",
        "Other models that I had tried in Project 1 were:\n",
        "* Single general model of feed forward architecture. It consisted of 4 layers, regularization, and an extensive hyperparameter tuning was done on it. Test RMSLE was way higher than validation.\n",
        "* 21 models for each combination of (n, k, m) but all feed forward. Even though this reduced the RMSLE, but it predicted same values for a combination of (n, k, m). Basically this model only learnt a value for each combination, which would minimize the loss.\n",
        "* As P is a matrix, I thought of using CNN, to have a 2D input. But this proved to be the most adverserial, having RMSLE even as high as 57. Thus, it proved that for m-height calculation, there is no spatial relationship between the matrix cell values."
      ],
      "metadata": {
        "id": "8KlJdDNyHy3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from tensorflow import keras\n",
        "from keras import layers, regularizers\n",
        "import tensorflow as tf\n",
        "\n",
        "'''\n",
        "  The dataset was saved to my google drive, so that I do not need to repeatedly\n",
        "  upload it to my Colab runtime.\n",
        "'''\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/My Drive/m_height_dataset.pkl'\n",
        "with open(file_path, 'rb') as f:\n",
        "    df = joblib.load(f)\n",
        "\n",
        "'''\n",
        "  Computing the maximum number of rows in P for Positional Encoding.\n",
        "  It is used to fix the size of one-hot encoding\n",
        "  This gets the maximum value seen across all samples,\n",
        "  so it must be 6 according to the project scope, else error in dataset generation.\n",
        "'''\n",
        "df['k_val'] = df['P'].apply(lambda x: x.shape[0])\n",
        "max_k = df['k_val'].max()\n",
        "print(f\"Maximum k (rows in P): {max_k}\")\n",
        "\n",
        "'''\n",
        "  Splitting the dataset here:\n",
        "  Test = 15% of df\n",
        "  Train = 85% * (85%) of df\n",
        "  Validation = 15% * (85%) of df\n",
        "'''\n",
        "train_val_df, test_df = train_test_split(df, test_size=0.15, random_state=42)\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.15, random_state=42)\n",
        "\n",
        "'''\n",
        "  The following preprocessing function:\n",
        "  Adds metadata (n, k, m) and positional encoding to each row of P\n",
        "  I tested without adding metadata, as anyways making individual models for each combination\n",
        "  But the results were adversarial with poor RMSLE values\n",
        "\n",
        "  Output shape: (k, feature_dim) where feature_dim = (columns in P + 3 metadata + max_k one-hot)\n",
        "  Target: log(h_m_C)\n",
        "  I tested the target without its log value, that is, the actual m-height.\n",
        "  But the RMSLE is better when the model is trained on log(m-height)\n",
        "'''\n",
        "def preprocess_group(group_df):\n",
        "    X_list, y_list = [], []\n",
        "    for _, row in group_df.iterrows():\n",
        "        # P has the shape (k, n-k)\n",
        "        P = np.array(row['P']).astype(np.float32)\n",
        "        n, k, m = row['n'], row['k'], row['m']\n",
        "        meta = np.array([n, k, m], dtype=np.float32)\n",
        "\n",
        "        row_features = []\n",
        "        for i in range(P.shape[0]):\n",
        "            pos_encoding = np.zeros(max_k)\n",
        "            # One-hot encoding the row index here\n",
        "            pos_encoding[i] = 1.0\n",
        "            features = np.concatenate([P[i], meta, pos_encoding])\n",
        "            row_features.append(features)\n",
        "\n",
        "        X = np.array(row_features)\n",
        "        X_list.append(X)\n",
        "        # Log scaling the target here\n",
        "        y_list.append(np.log(row['h_m_C']))\n",
        "    return np.array(X_list), np.array(y_list)\n",
        "\n",
        "'''\n",
        "  After much experimentation, developed a transformer based model.\n",
        "  This stems from the idea that m-height may depend on interactions between different rows.\n",
        "  Thus a transformer can model pairwise and gobal dependencies via self-attention.\n",
        "\n",
        "  Using transformer is better than fully connected layers alone because,\n",
        "  MLPs treat all rows flatly and independently,\n",
        "  CNNs assume local patterns, which is not present in a mathematical concept,\n",
        "  Thus transformers can learn attention weights dynamically across all rows.\n",
        "'''\n",
        "def build_transformer_model(input_shape):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    # Normalization\n",
        "    x = layers.LayerNormalization()(inputs)\n",
        "    # Self-attention\n",
        "    x = layers.MultiHeadAttention(num_heads=2, key_dim=8)(x, x)\n",
        "    # For variable-length inputs\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "    # Dense layer with L2 regularization\n",
        "    x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "    x = layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "    # Finally predict a single log(h_m_C) value\n",
        "    outputs = layers.Dense(1)(x)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    # MSE loss is being used in log-scale\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# Training, saving and evaluating model for each combination of (n, k, m) groups\n",
        "results = []\n",
        "unique_groups = sorted(train_df.groupby(['n', 'k', 'm']).groups.keys())\n",
        "\n",
        "os.makedirs('/content/models', exist_ok=True)\n",
        "\n",
        "for (n, k, m) in unique_groups:\n",
        "    print(f\"\\nTraining model for (n={n}, k={k}, m={m})\")\n",
        "\n",
        "    # Filtering group-specific data from each dataset split\n",
        "    train_group = train_df[(train_df['n'] == n) & (train_df['k'] == k) & (train_df['m'] == m)]\n",
        "    val_group = val_df[(val_df['n'] == n) & (val_df['k'] == k) & (val_df['m'] == m)]\n",
        "    test_group = test_df[(test_df['n'] == n) & (test_df['k'] == k) & (test_df['m'] == m)]\n",
        "\n",
        "    # Skipping groups which do not have even a single data, though this condition should never be reached\n",
        "    if len(train_group) == 0 or len(val_group) == 0 or len(test_group) == 0:\n",
        "        print(\"Skipping due to insufficient data.\")\n",
        "        continue\n",
        "\n",
        "    # Applying preprocessing on each split\n",
        "    X_train, y_train = preprocess_group(train_group)\n",
        "    X_val, y_val = preprocess_group(val_group)\n",
        "    X_test, y_test_log = preprocess_group(test_group)\n",
        "\n",
        "    # Training and model building\n",
        "    # Keeping epochs 30, as plotting training and validation loss curved showed not much change in loss after 27\n",
        "    model = build_transformer_model(input_shape=X_train.shape[1:])\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=30,\n",
        "        batch_size=32,\n",
        "        verbose=0,\n",
        "        callbacks=[keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]\n",
        "    )\n",
        "\n",
        "    model_path = f'/content/models/model_n{n}_k{k}_m{m}.h5'\n",
        "    model.save(model_path)\n",
        "    print(f\"Model saved to {model_path}\")\n",
        "\n",
        "    # Prediction on the test set\n",
        "    # Log base e value is predicted, which is converted to actual value\n",
        "    y_pred_log = model.predict(X_test).flatten()\n",
        "    y_pred = np.exp(y_pred_log)\n",
        "    y_true = np.exp(y_test_log)\n",
        "\n",
        "    # Clipping predictions to ensure valid domain for log2\n",
        "    y_pred = np.maximum(y_pred, 1.0)\n",
        "    y_true = np.maximum(y_true, 1.0)\n",
        "\n",
        "    # Computing RMSLE in log base 2 space\n",
        "    # This is done as the test cost function in the project scope suggests so\n",
        "    y_pred_log2 = np.log2(y_pred)\n",
        "    y_true_log2 = np.log2(y_true)\n",
        "    rmsle = np.sqrt(mean_squared_log_error(y_true_log2, y_pred_log2))\n",
        "    results.append(((n, k, m), rmsle))\n",
        "    print(f\"RMSLE (log base 2): {rmsle:.4f}\")\n",
        "\n",
        "print(\"\\n=== Summary of Results ===\")\n",
        "for (n, k, m), rmsle in results:\n",
        "    print(f\"Group (n={n}, k={k}, m={m}): RMSLE (log base 2) = {rmsle:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-npH4sqHz11",
        "outputId": "fa01fa43-ae39-4a6a-e833-7463a8eff425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Maximum k (rows in P): 6\n",
            "\n",
            "Training model for (n=9, k=4, m=2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n9_k4_m2.h5\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "RMSLE (log base 2): 0.0539\n",
            "\n",
            "Training model for (n=9, k=4, m=3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n9_k4_m3.h5\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "RMSLE (log base 2): 0.0522\n",
            "\n",
            "Training model for (n=9, k=4, m=4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n9_k4_m4.h5\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "RMSLE (log base 2): 0.0833\n",
            "\n",
            "Training model for (n=9, k=4, m=5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n9_k4_m5.h5\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "RMSLE (log base 2): 0.1157\n",
            "\n",
            "Training model for (n=9, k=5, m=2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n9_k5_m2.h5\n",
            "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.0503\n",
            "\n",
            "Training model for (n=9, k=5, m=3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n9_k5_m3.h5\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "RMSLE (log base 2): 0.0809\n",
            "\n",
            "Training model for (n=9, k=5, m=4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n9_k5_m4.h5\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.1095\n",
            "\n",
            "Training model for (n=9, k=6, m=2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n9_k6_m2.h5\n",
            "\u001b[1m394/394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "RMSLE (log base 2): 0.0716\n",
            "\n",
            "Training model for (n=9, k=6, m=3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n9_k6_m3.h5\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.1149\n",
            "\n",
            "Training model for (n=10, k=4, m=2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k4_m2.h5\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.1386\n",
            "\n",
            "Training model for (n=10, k=4, m=3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k4_m3.h5\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "RMSLE (log base 2): 0.0377\n",
            "\n",
            "Training model for (n=10, k=4, m=4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k4_m4.h5\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "RMSLE (log base 2): 0.0554\n",
            "\n",
            "Training model for (n=10, k=4, m=5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k4_m5.h5\n",
            "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.0825\n",
            "\n",
            "Training model for (n=10, k=4, m=6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k4_m6.h5\n",
            "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.1109\n",
            "\n",
            "Training model for (n=10, k=5, m=2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k5_m2.h5\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "RMSLE (log base 2): 0.0384\n",
            "\n",
            "Training model for (n=10, k=5, m=3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k5_m3.h5\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "RMSLE (log base 2): 0.0582\n",
            "\n",
            "Training model for (n=10, k=5, m=4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k5_m4.h5\n",
            "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.0790\n",
            "\n",
            "Training model for (n=10, k=5, m=5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k5_m5.h5\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "RMSLE (log base 2): 0.1049\n",
            "\n",
            "Training model for (n=10, k=6, m=2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k6_m2.h5\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.0500\n",
            "\n",
            "Training model for (n=10, k=6, m=3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k6_m3.h5\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.0767\n",
            "\n",
            "Training model for (n=10, k=6, m=4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/model_n10_k6_m4.h5\n",
            "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "RMSLE (log base 2): 0.1030\n",
            "\n",
            "=== Summary of Results ===\n",
            "Group (n=9, k=4, m=2): RMSLE (log base 2) = 0.0539\n",
            "Group (n=9, k=4, m=3): RMSLE (log base 2) = 0.0522\n",
            "Group (n=9, k=4, m=4): RMSLE (log base 2) = 0.0833\n",
            "Group (n=9, k=4, m=5): RMSLE (log base 2) = 0.1157\n",
            "Group (n=9, k=5, m=2): RMSLE (log base 2) = 0.0503\n",
            "Group (n=9, k=5, m=3): RMSLE (log base 2) = 0.0809\n",
            "Group (n=9, k=5, m=4): RMSLE (log base 2) = 0.1095\n",
            "Group (n=9, k=6, m=2): RMSLE (log base 2) = 0.0716\n",
            "Group (n=9, k=6, m=3): RMSLE (log base 2) = 0.1149\n",
            "Group (n=10, k=4, m=2): RMSLE (log base 2) = 0.1386\n",
            "Group (n=10, k=4, m=3): RMSLE (log base 2) = 0.0377\n",
            "Group (n=10, k=4, m=4): RMSLE (log base 2) = 0.0554\n",
            "Group (n=10, k=4, m=5): RMSLE (log base 2) = 0.0825\n",
            "Group (n=10, k=4, m=6): RMSLE (log base 2) = 0.1109\n",
            "Group (n=10, k=5, m=2): RMSLE (log base 2) = 0.0384\n",
            "Group (n=10, k=5, m=3): RMSLE (log base 2) = 0.0582\n",
            "Group (n=10, k=5, m=4): RMSLE (log base 2) = 0.0790\n",
            "Group (n=10, k=5, m=5): RMSLE (log base 2) = 0.1049\n",
            "Group (n=10, k=6, m=2): RMSLE (log base 2) = 0.0500\n",
            "Group (n=10, k=6, m=3): RMSLE (log base 2) = 0.0767\n",
            "Group (n=10, k=6, m=4): RMSLE (log base 2) = 0.1030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reasons I think this transformer based model works better tha any other because:\n",
        "* Enriching ecah row with Metadata (n, k, m) influences the m-height.\n",
        "* Positional encoding helps the model differentiate between rows and potentially learn row-wise importance or order effects.\n",
        "* The model seems to behave a little contextualized, position-aware features, and improves generalization and interpretability.\n",
        "* Using traditional MLPs would treat the input as flat and ignore row-level structure.\n",
        "* CNNs ae treating it like a grid, focusing on local row-wise patterns but here m-height is a global algebraic propert, not a spatial one.\n",
        "* Self attention is allowing the model to learn global dependencies, which is critical since any row could influence the m-height based on its interaction with any other.\n",
        "* Training individual models per (n, k, m) here avoids forcing a single model to learn a complex, multi-distribution space.. This in turn results in smaller, specalized models that overfit less and generalize better within each group.\n",
        "* from experiments, training on log(h_m_C) produces better results. This maybe due to it reducing skew and improving learning, especially since m-height values can vary exponentially.\n",
        "* L2 regularization in the dense layers and early stopping controls overfitting and prevents the model from memorizing small training sets in low-data regimes per group."
      ],
      "metadata": {
        "id": "upmnvpfIePTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next I generated another dataset of 100k rows, to further check how the model is performing on completely unseen data, and data that has been generated in a different session. This dataset was saved in my drive with the name 'm_height_dataset_1k.pkl'"
      ],
      "metadata": {
        "id": "X63t2zDzMBmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "from zipfile import ZipFile\n",
        "from google.colab import drive\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "\n",
        "'''\n",
        "  Usual preprocessing done before too while training\n",
        "'''\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "test_file_path = '/content/drive/My Drive/m_height_100k.pkl'\n",
        "with open(test_file_path, 'rb') as f:\n",
        "    test_df = joblib.load(f)\n",
        "\n",
        "\n",
        "# Fixing max_k based on analysis during training\n",
        "max_k = 6\n",
        "\n",
        "\n",
        "def preprocess_group(group_df):\n",
        "    X_list, y_list = [], []\n",
        "    for _, row in group_df.iterrows():\n",
        "        P = np.array(row['P']).astype(np.float32)\n",
        "        n, k, m = row['n'], row['k'], row['m']\n",
        "        meta = np.array([n, k, m], dtype=np.float32)\n",
        "\n",
        "        row_features = []\n",
        "        for i in range(P.shape[0]):\n",
        "            pos_encoding = np.zeros(max_k)\n",
        "            pos_encoding[i] = 1.0\n",
        "            features = np.concatenate([P[i], meta, pos_encoding])\n",
        "            row_features.append(features)\n",
        "\n",
        "        X = np.array(row_features)\n",
        "        X_list.append(X)\n",
        "        y_list.append(np.log(row['h_m_C']))\n",
        "    return np.array(X_list), np.array(y_list)\n",
        "\n",
        "'''\n",
        "  The final model was saved with the name 'models3.zip'.\n",
        "  That is now uploaded to runtime and unzipped.\n",
        "  The test data is first grouped into bins of each combinations\n",
        "  of (n, k, m), and then the pertaining model is invoked.\n",
        "'''\n",
        "model_zip_path = 'models3.zip'\n",
        "model_dir = 'models'\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "with ZipFile(model_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(model_dir)\n",
        "\n",
        "# These variables keep track of the evaluation metrics, globally across all models\n",
        "all_preds_log2 = []\n",
        "all_trues_log2 = []\n",
        "\n",
        "custom_objects = {'mse': keras.losses.MeanSquaredError()}\n",
        "# Splitting data into groups\n",
        "unique_groups = sorted(test_df.groupby(['n', 'k', 'm']).groups.keys())\n",
        "\n",
        "for (n, k, m) in unique_groups:\n",
        "    model_path = os.path.join(model_dir, f\"model_n{n}_k{k}_m{m}.h5\")\n",
        "    #This condition should not be reached, but an error check\n",
        "    if not os.path.exists(model_path):\n",
        "        continue\n",
        "\n",
        "    group_df = test_df[(test_df['n'] == n) & (test_df['k'] == k) & (test_df['m'] == m)]\n",
        "    if len(group_df) == 0:\n",
        "        continue\n",
        "\n",
        "    X_test, y_test_log = preprocess_group(group_df)\n",
        "    model = keras.models.load_model(model_path, custom_objects=custom_objects)\n",
        "\n",
        "    y_pred_log = model.predict(X_test).flatten()\n",
        "    y_pred = np.exp(y_pred_log)\n",
        "    y_true = np.exp(y_test_log)\n",
        "\n",
        "    y_pred = np.maximum(y_pred, 1.0)\n",
        "    y_true = np.maximum(y_true, 1.0)\n",
        "\n",
        "    all_preds_log2.extend(np.log2(y_pred))\n",
        "    all_trues_log2.extend(np.log2(y_true))\n",
        "\n",
        "    # To check the results, printing some actual vs predicted m-heights\n",
        "    print(f\"\\n--- Predictions for Group (n={n}, k={k}, m={m}) ---\")\n",
        "    num_samples = min(len(y_true), 5)\n",
        "    for i in range(num_samples):\n",
        "        print(f\"Sample {i+1}: Actual = {y_true[i]:.2f}, Predicted = {y_pred[i]:.2f}\")\n",
        "\n",
        "# Calculating all the metrics globally\n",
        "if all_preds_log2:\n",
        "    all_preds_log2 = np.array(all_preds_log2)\n",
        "    all_trues_log2 = np.array(all_trues_log2)\n",
        "\n",
        "    global_rmsle = np.sqrt(mean_squared_log_error(all_trues_log2, all_preds_log2))\n",
        "    avg_cost = np.mean((all_trues_log2 - all_preds_log2) ** 2)\n",
        "\n",
        "    print(\"\\n=== Global Test Evaluation ===\")\n",
        "    print(f\"Total Samples: {len(all_preds_log2)}\")\n",
        "    print(f\"Global Average Cost σ: {avg_cost:.4f}\")\n",
        "    print(f\"Global RMSLE (log base 2): {global_rmsle:.4f}\")\n",
        "else:\n",
        "    print(\"No valid predictions found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3CWmDwaLR5W",
        "outputId": "408df6e1-c90a-459e-cc35-85366199e0ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\n",
            "--- Predictions for Group (n=9, k=4, m=2) ---\n",
            "Sample 1: Actual = 194.03, Predicted = 170.31\n",
            "Sample 2: Actual = 175.25, Predicted = 132.05\n",
            "Sample 3: Actual = 152.03, Predicted = 157.95\n",
            "Sample 4: Actual = 176.14, Predicted = 159.20\n",
            "Sample 5: Actual = 183.21, Predicted = 152.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\n",
            "--- Predictions for Group (n=9, k=4, m=3) ---\n",
            "Sample 1: Actual = 210.28, Predicted = 270.19\n",
            "Sample 2: Actual = 177.91, Predicted = 270.64\n",
            "Sample 3: Actual = 220.43, Predicted = 260.80\n",
            "Sample 4: Actual = 252.63, Predicted = 289.72\n",
            "Sample 5: Actual = 215.02, Predicted = 253.29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\n",
            "--- Predictions for Group (n=9, k=4, m=4) ---\n",
            "Sample 1: Actual = 3134.83, Predicted = 1111.45\n",
            "Sample 2: Actual = 1434.17, Predicted = 933.10\n",
            "Sample 3: Actual = 1550.49, Predicted = 1034.68\n",
            "Sample 4: Actual = 1109.48, Predicted = 976.30\n",
            "Sample 5: Actual = 684.32, Predicted = 865.91\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\n",
            "--- Predictions for Group (n=9, k=4, m=5) ---\n",
            "Sample 1: Actual = 152304.11, Predicted = 21039.54\n",
            "Sample 2: Actual = 17305.33, Predicted = 25083.43\n",
            "Sample 3: Actual = 8202.88, Predicted = 20897.84\n",
            "Sample 4: Actual = 32600.17, Predicted = 24789.27\n",
            "Sample 5: Actual = 20170.64, Predicted = 23110.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\n",
            "--- Predictions for Group (n=9, k=5, m=2) ---\n",
            "Sample 1: Actual = 309.63, Predicted = 309.34\n",
            "Sample 2: Actual = 469.47, Predicted = 308.72\n",
            "Sample 3: Actual = 403.88, Predicted = 326.60\n",
            "Sample 4: Actual = 386.85, Predicted = 314.86\n",
            "Sample 5: Actual = 388.77, Predicted = 320.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
            "\n",
            "--- Predictions for Group (n=9, k=5, m=3) ---\n",
            "Sample 1: Actual = 978.70, Predicted = 1114.87\n",
            "Sample 2: Actual = 960.01, Predicted = 1088.54\n",
            "Sample 3: Actual = 1099.08, Predicted = 1044.18\n",
            "Sample 4: Actual = 868.14, Predicted = 1073.57\n",
            "Sample 5: Actual = 511.28, Predicted = 1008.66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
            "\n",
            "--- Predictions for Group (n=9, k=5, m=4) ---\n",
            "Sample 1: Actual = 2564955.57, Predicted = 32391.17\n",
            "Sample 2: Actual = 93582.35, Predicted = 34050.84\n",
            "Sample 3: Actual = 167199.64, Predicted = 34478.77\n",
            "Sample 4: Actual = 20684.01, Predicted = 31082.36\n",
            "Sample 5: Actual = 28919.13, Predicted = 33227.05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\n",
            "--- Predictions for Group (n=9, k=6, m=2) ---\n",
            "Sample 1: Actual = 525.49, Predicted = 886.65\n",
            "Sample 2: Actual = 471.29, Predicted = 796.70\n",
            "Sample 3: Actual = 434.34, Predicted = 766.85\n",
            "Sample 4: Actual = 587.23, Predicted = 716.12\n",
            "Sample 5: Actual = 911.90, Predicted = 651.78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\n",
            "--- Predictions for Group (n=9, k=6, m=3) ---\n",
            "Sample 1: Actual = 29425.84, Predicted = 18514.99\n",
            "Sample 2: Actual = 6838.80, Predicted = 19322.94\n",
            "Sample 3: Actual = 5219.96, Predicted = 18632.82\n",
            "Sample 4: Actual = 28336.84, Predicted = 18719.13\n",
            "Sample 5: Actual = 71185.12, Predicted = 18938.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "--- Predictions for Group (n=10, k=4, m=2) ---\n",
            "Sample 1: Actual = 14.81, Predicted = 59.94\n",
            "Sample 2: Actual = 103.84, Predicted = 56.25\n",
            "Sample 3: Actual = 126.22, Predicted = 56.89\n",
            "Sample 4: Actual = 120.04, Predicted = 60.63\n",
            "Sample 5: Actual = 112.29, Predicted = 63.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "--- Predictions for Group (n=10, k=4, m=3) ---\n",
            "Sample 1: Actual = 180.68, Predicted = 176.47\n",
            "Sample 2: Actual = 103.32, Predicted = 142.06\n",
            "Sample 3: Actual = 151.41, Predicted = 167.41\n",
            "Sample 4: Actual = 181.67, Predicted = 173.76\n",
            "Sample 5: Actual = 194.50, Predicted = 167.06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "--- Predictions for Group (n=10, k=4, m=4) ---\n",
            "Sample 1: Actual = 590.14, Predicted = 352.33\n",
            "Sample 2: Actual = 402.80, Predicted = 352.93\n",
            "Sample 3: Actual = 233.70, Predicted = 372.48\n",
            "Sample 4: Actual = 207.79, Predicted = 376.41\n",
            "Sample 5: Actual = 228.45, Predicted = 349.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "--- Predictions for Group (n=10, k=4, m=5) ---\n",
            "Sample 1: Actual = 2226.66, Predicted = 1338.92\n",
            "Sample 2: Actual = 868.86, Predicted = 1339.05\n",
            "Sample 3: Actual = 615.25, Predicted = 1328.85\n",
            "Sample 4: Actual = 6058.14, Predicted = 1431.89\n",
            "Sample 5: Actual = 833.53, Predicted = 1383.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "--- Predictions for Group (n=10, k=4, m=6) ---\n",
            "Sample 1: Actual = 26225.24, Predicted = 49576.61\n",
            "Sample 2: Actual = 61018.48, Predicted = 39249.80\n",
            "Sample 3: Actual = 16677.29, Predicted = 41298.32\n",
            "Sample 4: Actual = 34827.39, Predicted = 36813.87\n",
            "Sample 5: Actual = 103531.57, Predicted = 40649.76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\n",
            "--- Predictions for Group (n=10, k=5, m=2) ---\n",
            "Sample 1: Actual = 175.19, Predicted = 245.93\n",
            "Sample 2: Actual = 226.14, Predicted = 235.96\n",
            "Sample 3: Actual = 221.82, Predicted = 218.20\n",
            "Sample 4: Actual = 311.82, Predicted = 242.19\n",
            "Sample 5: Actual = 165.30, Predicted = 181.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\n",
            "--- Predictions for Group (n=10, k=5, m=3) ---\n",
            "Sample 1: Actual = 1502.48, Predicted = 482.48\n",
            "Sample 2: Actual = 460.90, Predicted = 470.83\n",
            "Sample 3: Actual = 370.51, Predicted = 477.84\n",
            "Sample 4: Actual = 440.30, Predicted = 474.80\n",
            "Sample 5: Actual = 633.06, Predicted = 471.73\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "--- Predictions for Group (n=10, k=5, m=4) ---\n",
            "Sample 1: Actual = 3283.15, Predicted = 2201.54\n",
            "Sample 2: Actual = 1513.29, Predicted = 2028.42\n",
            "Sample 3: Actual = 3004.40, Predicted = 2027.26\n",
            "Sample 4: Actual = 5171.45, Predicted = 1939.58\n",
            "Sample 5: Actual = 1494.52, Predicted = 2051.57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "--- Predictions for Group (n=10, k=5, m=5) ---\n",
            "Sample 1: Actual = 177047.48, Predicted = 70163.84\n",
            "Sample 2: Actual = 246821.81, Predicted = 70372.19\n",
            "Sample 3: Actual = 23983.40, Predicted = 69214.73\n",
            "Sample 4: Actual = 29059.81, Predicted = 72192.05\n",
            "Sample 5: Actual = 41024.03, Predicted = 72784.98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\n",
            "--- Predictions for Group (n=10, k=6, m=2) ---\n",
            "Sample 1: Actual = 738.55, Predicted = 436.10\n",
            "Sample 2: Actual = 413.91, Predicted = 449.45\n",
            "Sample 3: Actual = 285.07, Predicted = 405.66\n",
            "Sample 4: Actual = 1027.39, Predicted = 403.71\n",
            "Sample 5: Actual = 874.60, Predicted = 492.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\n",
            "--- Predictions for Group (n=10, k=6, m=3) ---\n",
            "Sample 1: Actual = 1619.49, Predicted = 1850.11\n",
            "Sample 2: Actual = 1884.39, Predicted = 1728.86\n",
            "Sample 3: Actual = 1319.60, Predicted = 1773.84\n",
            "Sample 4: Actual = 1010.55, Predicted = 1592.58\n",
            "Sample 5: Actual = 4016.91, Predicted = 1752.02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\n",
            "--- Predictions for Group (n=10, k=6, m=4) ---\n",
            "Sample 1: Actual = 137656.18, Predicted = 68381.42\n",
            "Sample 2: Actual = 40116.68, Predicted = 65603.41\n",
            "Sample 3: Actual = 31498.34, Predicted = 69660.20\n",
            "Sample 4: Actual = 485405.97, Predicted = 67977.70\n",
            "Sample 5: Actual = 246626.37, Predicted = 68896.18\n",
            "\n",
            "=== Global Test Evaluation ===\n",
            "Total Samples: 100000\n",
            "Global Average Cost σ: 1.4477\n",
            "Global RMSLE (log base 2): 0.0853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next cell runs the evaluation on the test set. As said in the project scope, upload the models directory shared, named, '436000715_models.zip'.\n",
        "The function call has been done. Just update the dictionary 'inputs', to your evaluation dictionary. The format has been followed as in the template. Next, the cell returns a dictionary as output, and prints it.\n",
        "\n",
        "After inserting your input in the placeholder, and uploading the zip file, run the following cell."
      ],
      "metadata": {
        "id": "2zX1ztJiDnRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "from zipfile import ZipFile\n",
        "from google.colab import drive\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "\n",
        "def predict_m_heights(inputs, model_dir, max_k=6):\n",
        "    outputs = {}\n",
        "    custom_objects = {'mse': keras.losses.MeanSquaredError()}\n",
        "\n",
        "    for key, matrices in inputs.items():\n",
        "        # Extracting n, k, m from the dictionary\n",
        "        n, k, m = eval(key)\n",
        "        model_path = os.path.join(model_dir, f\"model_n{n}_k{k}_m{m}.h5\")\n",
        "\n",
        "        # Skipping, in case model is not found\n",
        "        if not os.path.exists(model_path):\n",
        "            print(f\"Model for group (n={n}, k={k}, m={m}) not found.\")\n",
        "            continue\n",
        "\n",
        "        # Loading the model here\n",
        "        model = keras.models.load_model(model_path, custom_objects=custom_objects)\n",
        "        preds = []\n",
        "\n",
        "        # Preprocessing the P_list\n",
        "        for P in matrices:\n",
        "            P = np.array(P).astype(np.float32)\n",
        "            meta = np.array([n, k, m], dtype=np.float32)\n",
        "\n",
        "            row_features = []\n",
        "            for i in range(P.shape[0]):\n",
        "                pos_encoding = np.zeros(max_k)\n",
        "                pos_encoding[i] = 1.0\n",
        "                features = np.concatenate([P[i], meta, pos_encoding])\n",
        "                row_features.append(features)\n",
        "\n",
        "            X = np.array([row_features])\n",
        "            y_pred_log = model.predict(X, verbose=0).flatten()[0]\n",
        "            y_pred = np.exp(y_pred_log)\n",
        "            y_pred = max(1.0, y_pred)\n",
        "            preds.append(y_pred)\n",
        "\n",
        "        outputs[key] = preds\n",
        "\n",
        "    return outputs\n",
        "\n",
        "\n",
        "# Sample input is shown, modify the input with test set here\n",
        "'''\n",
        "inputs = {\n",
        "    '[9,6,3]': [\n",
        "        np.array([\n",
        "            [ 0.4759809,  0.9938236, 0.819425 ],\n",
        "            [-0.8960798, -0.7442706, 0.3345122],\n",
        "            [ 0.4759809,  0.9938236, 0.819425 ],\n",
        "            [-0.8960798, -0.7442706, 0.3345122],\n",
        "            [ 0.4759809,  0.9938236, 0.819425 ],\n",
        "            [-0.8960798, -0.7442706, 0.3345122],\n",
        "        ]),\n",
        "        # Add more P matrices here if needed\n",
        "\n",
        "    ],\n",
        "}\n",
        "'''\n",
        "# Insert here\n",
        "inputs = {\n",
        "\n",
        "}\n",
        "\n",
        "model_zip_path = '436000715_models.zip'\n",
        "model_dir = 'models'\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "with ZipFile(model_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(model_dir)\n",
        "\n",
        "# Calling the required function here\n",
        "outputs = predict_m_heights(inputs, model_dir, max_k=6)\n",
        "\n",
        "print(\"\\n=== Outputs ===\")\n",
        "for key in outputs:\n",
        "    preds = [float(x) for x in outputs[key]]\n",
        "    print(f\"{key} => {preds}\")"
      ],
      "metadata": {
        "id": "gy7eJZZq08HO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d01ef256-ade5-47ec-beb4-b94c25b4bc40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Outputs ===\n",
            "[9,6,3] => [4725.53173828125]\n"
          ]
        }
      ]
    }
  ]
}